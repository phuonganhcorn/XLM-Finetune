{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-n5j_FOVeMSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89050f79-089e-444e-d25f-14eaa7be5bfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/drive/MyDrive/\n",
        "!git clone https://github.com/phuonganhcorn/XLM-Finetune"
      ],
      "metadata": {
        "id": "ymy-h7gQjm69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "364ea495-9b86-46d6-9578-f4dbc00651d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'XLM-Finetune'...\n",
            "remote: Enumerating objects: 267, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
            "remote: Total 267 (delta 9), reused 9 (delta 3), pack-reused 242\u001b[K\n",
            "Receiving objects: 100% (267/267), 131.56 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (52/52), done.\n",
            "Updating files: 100% (222/222), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r /content/XLM-Finetune/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JY9yMJ7oj8uh",
        "outputId": "3c653d47-97d7-4723-9388-52a3038c965e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from -r /content/XLM-Finetune/requirements.txt (line 1)) (3.8.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r /content/XLM-Finetune/requirements.txt (line 2)) (1.11.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r /content/XLM-Finetune/requirements.txt (line 3)) (4.35.2)\n",
            "Collecting datasets (from -r /content/XLM-Finetune/requirements.txt (line 4))\n",
            "  Downloading datasets-2.16.1-py3-none-any.whl (507 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.1/507.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r /content/XLM-Finetune/requirements.txt (line 5)) (2.15.1)\n",
            "Collecting tensorboardX (from -r /content/XLM-Finetune/requirements.txt (line 6))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate (from -r /content/XLM-Finetune/requirements.txt (line 7))\n",
            "  Downloading accelerate-0.26.1-py3-none-any.whl (270 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->-r /content/XLM-Finetune/requirements.txt (line 1)) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->-r /content/XLM-Finetune/requirements.txt (line 1)) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->-r /content/XLM-Finetune/requirements.txt (line 1)) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk->-r /content/XLM-Finetune/requirements.txt (line 1)) (4.66.1)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy->-r /content/XLM-Finetune/requirements.txt (line 2)) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (0.20.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (0.4.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (10.0.1)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (0.6)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4))\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (3.4.1)\n",
            "Collecting multiprocess (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4))\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (1.60.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (3.5.1)\n",
            "Requirement already satisfied: protobuf<4.24,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (3.0.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r /content/XLM-Finetune/requirements.txt (line 7)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r /content/XLM-Finetune/requirements.txt (line 7)) (2.1.0+cu121)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->-r /content/XLM-Finetune/requirements.txt (line 3)) (2023.11.17)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r /content/XLM-Finetune/requirements.txt (line 7)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r /content/XLM-Finetune/requirements.txt (line 7)) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r /content/XLM-Finetune/requirements.txt (line 7)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate->-r /content/XLM-Finetune/requirements.txt (line 7)) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r /content/XLM-Finetune/requirements.txt (line 4)) (2023.3.post1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r /content/XLM-Finetune/requirements.txt (line 5)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate->-r /content/XLM-Finetune/requirements.txt (line 7)) (1.3.0)\n",
            "Installing collected packages: tensorboardX, dill, multiprocess, accelerate, datasets\n",
            "Successfully installed accelerate-0.26.1 datasets-2.16.1 dill-0.3.7 multiprocess-0.70.15 tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q datasets"
      ],
      "metadata": {
        "id": "W-B29sZWkq7s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f75dfc03-2866-4908-e95f-6af63b69c3ba"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for accelerate (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "noU_yeZXx_Eq",
        "outputId": "11661c86-5608-4b60-c828-7ad1025c0d93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⏬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.1.0-1/Mambaforge-23.1.0-1-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:13\n",
            "🔁 Restarting kernel...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBn1dx0ryZjG",
        "outputId": "55e75c7f-49ae-42cf-fb44-17074a31aa4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conda 23.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install -q torch==1.9.0 torchvision==0.10.0 torchaudio==0.9.0 -c pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VItpW86Rybwm",
        "outputId": "a2dc4da9-94a2-4d42-c9d6-98fe16abd4da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): ...working... WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
            "done\n",
            "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): ...working... WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\n",
            "WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.6.0.*, but conda is ignoring the .* and treating it as 1.6.0\n",
            "WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\n",
            "done\n",
            "Solving environment: ...working... failed with initial frozen solve. Retrying with flexible solve.\n",
            "\n",
            "PackagesNotFoundError: The following packages are not available from current channels:\n",
            "\n",
            "  - torch==1.9.0\n",
            "\n",
            "Current channels:\n",
            "\n",
            "  - https://conda.anaconda.org/pytorch/linux-64\n",
            "  - https://conda.anaconda.org/pytorch/noarch\n",
            "  - https://conda.anaconda.org/conda-forge/linux-64\n",
            "  - https://conda.anaconda.org/conda-forge/noarch\n",
            "\n",
            "To search for alternate channels that may provide the conda package you're\n",
            "looking for, navigate to\n",
            "\n",
            "    https://anaconda.org\n",
            "\n",
            "and use the search bar at the top of the page.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!conda install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LGG3tJ-0Gum",
        "outputId": "98639915-c832-4544-e332-5e252b2d7902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "Collecting package metadata (repodata.json): / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Solving environment: / \b\bfailed with initial frozen solve. Retrying with flexible solve.\n",
            "\n",
            "PackagesNotFoundError: The following packages are not available from current channels:\n",
            "\n",
            "  - torch\n",
            "\n",
            "Current channels:\n",
            "\n",
            "  - https://conda.anaconda.org/conda-forge/linux-64\n",
            "  - https://conda.anaconda.org/conda-forge/noarch\n",
            "\n",
            "To search for alternate channels that may provide the conda package you're\n",
            "looking for, navigate to\n",
            "\n",
            "    https://anaconda.org\n",
            "\n",
            "and use the search bar at the top of the page.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch # test torch"
      ],
      "metadata": {
        "id": "9Xu4eKKc0jGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/XLM-Finetune/utils/squad_to_mrc.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks5cnv-c097K",
        "outputId": "a91f22c0-bc90-435e-d887-4e9bd7dde423"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Chunk /content/XLM-Finetune/data-bin/raw/squad/dev-context-en-question-vi.json: 100% 228/228 [00:01<00:00, 163.08it/s]\n",
            "511\n",
            "Chunk /content/XLM-Finetune/data-bin/raw/squad/test-context-en-question-vi.json: 100% 2454/2454 [00:07<00:00, 342.65it/s]\n",
            "5495\n",
            "Chunk /content/XLM-Finetune/data-bin/raw/squad/test-context-vi-question-en.json: 100% 2454/2454 [00:05<00:00, 444.68it/s]\n",
            "5495\n",
            "Chunk /content/XLM-Finetune/data-bin/raw/squad/train_qa_vi_mailong.json: 100% 526/526 [00:00<00:00, 742.30it/s]\n",
            "3454\n",
            "Chunk /content/XLM-Finetune/data-bin/raw/squad/dev-context-vi-question-en.json: 100% 228/228 [00:00<00:00, 820.34it/s]\n",
            "511\n",
            "Total: 15466 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/XLM-Finetune/utils/train_valid_split.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAUy1zOR1_EK",
        "outputId": "4f0b1b7c-eadf-46db-b818-bf29c945692c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 13919 samples\n",
            "Valid: 1547 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
        "!wget https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vccLGVGz4gWf",
        "outputId": "8822afed-677b-4a6c-e783-71230f428000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-12-25 07:31:25--  https://download.pytorch.org/whl/cu111/torch-1.9.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.86.38.37, 99.86.38.106, 99.86.38.72, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.86.38.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2041342154 (1.9G) [binary/octet-stream]\n",
            "Saving to: ‘torch-1.9.0+cu111-cp37-cp37m-linux_x86_64.whl’\n",
            "\n",
            "torch-1.9.0+cu111-c 100%[===================>]   1.90G  97.3MB/s    in 21s     \n",
            "\n",
            "2023-12-25 07:31:47 (92.4 MB/s) - ‘torch-1.9.0+cu111-cp37-cp37m-linux_x86_64.whl’ saved [2041342154/2041342154]\n",
            "\n",
            "--2023-12-25 07:31:47--  https://download.pytorch.org/whl/cu111/torchvision-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "Resolving download.pytorch.org (download.pytorch.org)... 99.86.38.37, 99.86.38.106, 99.86.38.72, ...\n",
            "Connecting to download.pytorch.org (download.pytorch.org)|99.86.38.37|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23185811 (22M) [binary/octet-stream]\n",
            "Saving to: ‘torchvision-0.10.0+cu111-cp37-cp37m-linux_x86_64.whl’\n",
            "\n",
            "torchvision-0.10.0+ 100%[===================>]  22.11M  89.9MB/s    in 0.2s    \n",
            "\n",
            "2023-12-25 07:31:47 (89.9 MB/s) - ‘torchvision-0.10.0+cu111-cp37-cp37m-linux_x86_64.whl’ saved [23185811/23185811]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VnZkdC8S46gV",
        "outputId": "846e8a95-8cb6-46b7-9ebf-f46c1165cac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-xla==2.0\n",
            "  Downloading https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl (162.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.9/162.9 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloud-tpu-client==0.10\n",
            "  Downloading cloud_tpu_client-0.10-py3-none-any.whl (7.4 kB)\n",
            "Collecting torch==2.0.0\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1\n",
            "  Downloading torchvision-0.15.1-cp310-cp310-manylinux1_x86_64.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-python-client==1.8.0\n",
            "  Downloading google_api_python_client-1.8.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauth2client\n",
            "  Downloading oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/site-packages (from torch==2.0.0) (4.9.0)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from torch==2.0.0) (3.13.1)\n",
            "Collecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m110.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow!=8.3.*,>=5.3.0\n",
            "  Downloading Pillow-10.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m110.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from torchvision==0.15.1) (2.28.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from torchvision==0.15.1) (1.26.2)\n",
            "Collecting httplib2<1dev,>=0.9.2\n",
            "  Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core<2dev,>=1.13.0\n",
            "  Downloading google_api_core-1.34.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.2/120.2 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (1.16.0)\n",
            "Collecting uritemplate<4dev,>=3.0.0\n",
            "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: google-auth>=1.4.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client==1.8.0->cloud-tpu-client==0.10) (2.25.2)\n",
            "Collecting google-auth-httplib2>=0.0.3\n",
            "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (65.6.3)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0) (0.40.0)\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.3/26.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-17.0.6.tar.gz (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/site-packages (from torch-xla==2.0) (2.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/site-packages (from jinja2->torch==2.0.0) (2.1.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client==0.10) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client==0.10) (0.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/site-packages (from oauth2client->cloud-tpu-client==0.10) (0.5.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->torchvision==0.15.1) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->torchvision==0.15.1) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->torchvision==0.15.1) (3.1.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->torchvision==0.15.1) (2022.12.7)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<4.0.0dev,>=3.19.5\n",
            "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.62.0-py2.py3-none-any.whl (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.7/228.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth>=1.4.1->google-api-python-client==1.8.0->cloud-tpu-client==0.10) (5.3.2)\n",
            "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2\n",
            "  Downloading pyparsing-3.1.1-py3-none-any.whl (103 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: lit\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=4f570a6589bcf3002119d7cd64b5da6d488c13966e1a7a65d82c654431c14f6a\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/dd/04/47d42976a6a86dc2ab66d7518621ae96f43452c8841d74758a\n",
            "Successfully built lit\n",
            "Installing collected packages: mpmath, lit, cmake, uritemplate, sympy, pyparsing, protobuf, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, httplib2, googleapis-common-protos, oauth2client, google-auth-httplib2, google-api-core, google-api-python-client, cloud-tpu-client, torch-xla, triton, torch, torchvision\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.23.4\n",
            "    Uninstalling protobuf-4.23.4:\n",
            "      Successfully uninstalled protobuf-4.23.4\n",
            "Successfully installed cloud-tpu-client-0.10 cmake-3.28.1 google-api-core-1.34.0 google-api-python-client-1.8.0 google-auth-httplib2-0.2.0 googleapis-common-protos-1.62.0 httplib2-0.22.0 jinja2-3.1.2 lit-17.0.6 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 oauth2client-4.1.3 pillow-10.1.0 protobuf-3.20.3 pyparsing-3.1.1 sympy-1.12 torch-2.0.0 torch-xla-2.0.0.dev20230516+colab torchvision-0.15.1 triton-2.0.0 uritemplate-3.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "httplib2",
                  "mpmath",
                  "sympy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -qU"
      ],
      "metadata": {
        "id": "C9VKQ1KUoPW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f512e4cd-a32d-4081-ca68-761ac6301209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/270.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m194.6/270.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/XLM-Finetune/main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slF4xGhn3pNY",
        "outputId": "0e625f4b-7910-403e-82d7-86b41478ccee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-15 11:50:05.236895: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-15 11:50:05.236950: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-15 11:50:05.238289: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-15 11:50:06.436774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of MRCQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Train set:  13919\n",
            "Valid set:  1547\n",
            "Map (num_proc=10): 100% 13919/13919 [02:22<00:00, 97.55 examples/s] \n",
            "Filter (num_proc=10): 100% 13919/13919 [00:05<00:00, 2693.31 examples/s]\n",
            "Train set:  13078\n",
            "Valid set:  1466\n",
            "{'loss': 5.6923, 'learning_rate': 1.9113149847094802e-07, 'epoch': 0.0}\n",
            "{'loss': 5.5649, 'learning_rate': 3.8226299694189603e-07, 'epoch': 0.0}\n",
            "{'loss': 5.2566, 'learning_rate': 5.733944954128441e-07, 'epoch': 0.0}\n",
            "{'loss': 5.1639, 'learning_rate': 7.645259938837921e-07, 'epoch': 0.0}\n",
            "{'loss': 5.1615, 'learning_rate': 9.556574923547401e-07, 'epoch': 0.0}\n",
            "{'loss': 4.9316, 'learning_rate': 1.1467889908256882e-06, 'epoch': 0.0}\n",
            "{'loss': 4.7821, 'learning_rate': 1.3379204892966363e-06, 'epoch': 0.0}\n",
            "{'loss': 4.4025, 'learning_rate': 1.5290519877675841e-06, 'epoch': 0.0}\n",
            "{'loss': 4.0383, 'learning_rate': 1.7201834862385322e-06, 'epoch': 0.0}\n",
            "{'loss': 3.4557, 'learning_rate': 1.9113149847094803e-06, 'epoch': 0.0}\n",
            "{'loss': 5.7639, 'learning_rate': 2.1024464831804283e-06, 'epoch': 0.0}\n",
            "{'loss': 5.6257, 'learning_rate': 2.2935779816513764e-06, 'epoch': 0.0}\n",
            "{'loss': 5.271, 'learning_rate': 2.484709480122324e-06, 'epoch': 0.0}\n",
            "{'loss': 5.0253, 'learning_rate': 2.6758409785932725e-06, 'epoch': 0.01}\n",
            "{'loss': 4.9182, 'learning_rate': 2.8669724770642206e-06, 'epoch': 0.01}\n",
            "{'loss': 5.0955, 'learning_rate': 3.0581039755351682e-06, 'epoch': 0.01}\n",
            "{'loss': 4.5443, 'learning_rate': 3.249235474006116e-06, 'epoch': 0.01}\n",
            "{'loss': 4.2119, 'learning_rate': 3.4403669724770644e-06, 'epoch': 0.01}\n",
            "{'loss': 3.5163, 'learning_rate': 3.6314984709480124e-06, 'epoch': 0.01}\n",
            "{'loss': 3.1553, 'learning_rate': 3.8226299694189605e-06, 'epoch': 0.01}\n",
            "{'loss': 5.5414, 'learning_rate': 4.013761467889909e-06, 'epoch': 0.01}\n",
            "{'loss': 5.2775, 'learning_rate': 4.204892966360857e-06, 'epoch': 0.01}\n",
            "{'loss': 5.0249, 'learning_rate': 4.396024464831804e-06, 'epoch': 0.01}\n",
            "{'loss': 5.0411, 'learning_rate': 4.587155963302753e-06, 'epoch': 0.01}\n",
            "{'loss': 4.9966, 'learning_rate': 4.778287461773701e-06, 'epoch': 0.01}\n",
            "{'loss': 5.4383, 'learning_rate': 4.969418960244648e-06, 'epoch': 0.01}\n",
            "{'loss': 4.0724, 'learning_rate': 5.160550458715597e-06, 'epoch': 0.01}\n",
            "{'loss': 4.0755, 'learning_rate': 5.351681957186545e-06, 'epoch': 0.01}\n",
            "{'loss': 3.3944, 'learning_rate': 5.542813455657492e-06, 'epoch': 0.01}\n",
            "{'loss': 2.6654, 'learning_rate': 5.733944954128441e-06, 'epoch': 0.01}\n",
            "{'loss': 5.2094, 'learning_rate': 5.925076452599388e-06, 'epoch': 0.01}\n",
            "{'loss': 5.8186, 'learning_rate': 6.1162079510703365e-06, 'epoch': 0.01}\n",
            "{'loss': 4.4389, 'learning_rate': 6.3073394495412846e-06, 'epoch': 0.01}\n",
            "{'loss': 4.7046, 'learning_rate': 6.498470948012232e-06, 'epoch': 0.01}\n",
            "{'loss': 5.0166, 'learning_rate': 6.6896024464831815e-06, 'epoch': 0.01}\n",
            "{'loss': 4.7329, 'learning_rate': 6.880733944954129e-06, 'epoch': 0.01}\n",
            "{'loss': 3.5578, 'learning_rate': 7.071865443425077e-06, 'epoch': 0.01}\n",
            "{'loss': 3.9069, 'learning_rate': 7.262996941896025e-06, 'epoch': 0.01}\n",
            "{'loss': 3.4181, 'learning_rate': 7.454128440366973e-06, 'epoch': 0.01}\n",
            "{'loss': 3.0273, 'learning_rate': 7.645259938837921e-06, 'epoch': 0.02}\n",
            "{'loss': 5.5775, 'learning_rate': 7.836391437308869e-06, 'epoch': 0.02}\n",
            "{'loss': 5.4277, 'learning_rate': 8.027522935779817e-06, 'epoch': 0.02}\n",
            "{'loss': 4.8136, 'learning_rate': 8.218654434250765e-06, 'epoch': 0.02}\n",
            "{'loss': 4.3398, 'learning_rate': 8.409785932721713e-06, 'epoch': 0.02}\n",
            "{'loss': 3.7111, 'learning_rate': 8.600917431192661e-06, 'epoch': 0.02}\n",
            "{'loss': 4.6783, 'learning_rate': 8.792048929663608e-06, 'epoch': 0.02}\n",
            "{'loss': 3.3771, 'learning_rate': 8.983180428134556e-06, 'epoch': 0.02}\n",
            "{'loss': 3.3813, 'learning_rate': 9.174311926605506e-06, 'epoch': 0.02}\n",
            "{'loss': 3.0434, 'learning_rate': 9.365443425076454e-06, 'epoch': 0.02}\n",
            "{'loss': 2.5235, 'learning_rate': 9.556574923547402e-06, 'epoch': 0.02}\n",
            "{'loss': 4.4829, 'learning_rate': 9.74770642201835e-06, 'epoch': 0.02}\n",
            "{'loss': 6.6236, 'learning_rate': 9.938837920489296e-06, 'epoch': 0.02}\n",
            "{'loss': 4.9446, 'learning_rate': 1.0129969418960244e-05, 'epoch': 0.02}\n",
            "{'loss': 4.928, 'learning_rate': 1.0321100917431194e-05, 'epoch': 0.02}\n",
            "{'loss': 3.5005, 'learning_rate': 1.0512232415902142e-05, 'epoch': 0.02}\n",
            "{'loss': 3.8593, 'learning_rate': 1.070336391437309e-05, 'epoch': 0.02}\n",
            "{'loss': 3.2463, 'learning_rate': 1.0894495412844036e-05, 'epoch': 0.02}\n",
            "{'loss': 3.0242, 'learning_rate': 1.1085626911314985e-05, 'epoch': 0.02}\n",
            "{'loss': 2.1659, 'learning_rate': 1.1276758409785933e-05, 'epoch': 0.02}\n",
            "{'loss': 0.6177, 'learning_rate': 1.1467889908256882e-05, 'epoch': 0.02}\n",
            "{'loss': 4.2266, 'learning_rate': 1.165902140672783e-05, 'epoch': 0.02}\n",
            "{'loss': 4.9831, 'learning_rate': 1.1850152905198777e-05, 'epoch': 0.02}\n",
            "{'loss': 5.6731, 'learning_rate': 1.2041284403669725e-05, 'epoch': 0.02}\n",
            "{'loss': 4.0026, 'learning_rate': 1.2232415902140673e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4167, 'learning_rate': 1.2423547400611621e-05, 'epoch': 0.02}\n",
            "{'loss': 2.7594, 'learning_rate': 1.2614678899082569e-05, 'epoch': 0.03}\n",
            "{'loss': 1.5348, 'learning_rate': 1.2805810397553517e-05, 'epoch': 0.03}\n",
            "{'loss': 2.7965, 'learning_rate': 1.2996941896024464e-05, 'epoch': 0.03}\n",
            "{'loss': 2.6535, 'learning_rate': 1.3188073394495412e-05, 'epoch': 0.03}\n",
            "{'loss': 4.4727, 'learning_rate': 1.3379204892966363e-05, 'epoch': 0.03}\n",
            "{'loss': 5.2678, 'learning_rate': 1.3570336391437311e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3558, 'learning_rate': 1.3761467889908258e-05, 'epoch': 0.03}\n",
            "{'loss': 4.5982, 'learning_rate': 1.3952599388379206e-05, 'epoch': 0.03}\n",
            "{'loss': 5.0284, 'learning_rate': 1.4143730886850154e-05, 'epoch': 0.03}\n",
            "{'loss': 4.0193, 'learning_rate': 1.4334862385321102e-05, 'epoch': 0.03}\n",
            "{'loss': 3.9744, 'learning_rate': 1.452599388379205e-05, 'epoch': 0.03}\n",
            "{'loss': 2.7716, 'learning_rate': 1.4717125382262998e-05, 'epoch': 0.03}\n",
            "{'loss': 4.0044, 'learning_rate': 1.4908256880733946e-05, 'epoch': 0.03}\n",
            "{'loss': 2.1649, 'learning_rate': 1.5099388379204892e-05, 'epoch': 0.03}\n",
            "{'loss': 1.1499, 'learning_rate': 1.5290519877675842e-05, 'epoch': 0.03}\n",
            "{'loss': 4.856, 'learning_rate': 1.548165137614679e-05, 'epoch': 0.03}\n",
            "{'loss': 4.2218, 'learning_rate': 1.5672782874617738e-05, 'epoch': 0.03}\n",
            "{'loss': 3.731, 'learning_rate': 1.5863914373088686e-05, 'epoch': 0.03}\n",
            "{'loss': 4.3645, 'learning_rate': 1.6055045871559634e-05, 'epoch': 0.03}\n",
            "{'loss': 3.1759, 'learning_rate': 1.6246177370030582e-05, 'epoch': 0.03}\n",
            "{'loss': 2.1521, 'learning_rate': 1.643730886850153e-05, 'epoch': 0.03}\n",
            "{'loss': 2.8455, 'learning_rate': 1.662844036697248e-05, 'epoch': 0.03}\n",
            "{'loss': 2.9074, 'learning_rate': 1.6819571865443427e-05, 'epoch': 0.03}\n",
            "{'loss': 3.3139, 'learning_rate': 1.7010703363914375e-05, 'epoch': 0.03}\n",
            "{'loss': 2.4967, 'learning_rate': 1.7201834862385323e-05, 'epoch': 0.03}\n",
            "{'loss': 4.9184, 'learning_rate': 1.739296636085627e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2046, 'learning_rate': 1.7584097859327215e-05, 'epoch': 0.04}\n",
            "{'loss': 3.8088, 'learning_rate': 1.7775229357798164e-05, 'epoch': 0.04}\n",
            "{'loss': 3.9958, 'learning_rate': 1.796636085626911e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4896, 'learning_rate': 1.8157492354740063e-05, 'epoch': 0.04}\n",
            "{'loss': 2.1684, 'learning_rate': 1.834862385321101e-05, 'epoch': 0.04}\n",
            "{'loss': 2.8289, 'learning_rate': 1.853975535168196e-05, 'epoch': 0.04}\n",
            "{'loss': 2.5169, 'learning_rate': 1.8730886850152907e-05, 'epoch': 0.04}\n",
            "{'loss': 2.4557, 'learning_rate': 1.8922018348623855e-05, 'epoch': 0.04}\n",
            "{'loss': 1.567, 'learning_rate': 1.9113149847094803e-05, 'epoch': 0.04}\n",
            "{'loss': 3.8746, 'learning_rate': 1.930428134556575e-05, 'epoch': 0.04}\n",
            "{'loss': 3.8956, 'learning_rate': 1.94954128440367e-05, 'epoch': 0.04}\n",
            "{'loss': 3.0333, 'learning_rate': 1.9686544342507644e-05, 'epoch': 0.04}\n",
            "{'loss': 3.6959, 'learning_rate': 1.9877675840978592e-05, 'epoch': 0.04}\n",
            "{'loss': 2.1452, 'learning_rate': 2.006880733944954e-05, 'epoch': 0.04}\n",
            "{'loss': 2.817, 'learning_rate': 2.025993883792049e-05, 'epoch': 0.04}\n",
            "{'loss': 1.9637, 'learning_rate': 2.045107033639144e-05, 'epoch': 0.04}\n",
            "{'loss': 5.0718, 'learning_rate': 2.0642201834862388e-05, 'epoch': 0.04}\n",
            "{'loss': 1.8835, 'learning_rate': 2.0833333333333336e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4874, 'learning_rate': 2.1024464831804284e-05, 'epoch': 0.04}\n",
            "{'loss': 5.8221, 'learning_rate': 2.1215596330275232e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4193, 'learning_rate': 2.140672782874618e-05, 'epoch': 0.04}\n",
            "{'loss': 5.5379, 'learning_rate': 2.1597859327217125e-05, 'epoch': 0.04}\n",
            "{'loss': 3.8081, 'learning_rate': 2.1788990825688073e-05, 'epoch': 0.04}\n",
            "{'loss': 3.1404, 'learning_rate': 2.198012232415902e-05, 'epoch': 0.04}\n",
            "{'loss': 2.5159, 'learning_rate': 2.217125382262997e-05, 'epoch': 0.04}\n",
            "{'loss': 1.8653, 'learning_rate': 2.2362385321100917e-05, 'epoch': 0.04}\n",
            "{'loss': 2.8995, 'learning_rate': 2.2553516819571865e-05, 'epoch': 0.05}\n",
            "{'loss': 0.7896, 'learning_rate': 2.2744648318042813e-05, 'epoch': 0.05}\n",
            "{'loss': 0.2443, 'learning_rate': 2.2935779816513765e-05, 'epoch': 0.05}\n",
            "{'loss': 4.4817, 'learning_rate': 2.3126911314984713e-05, 'epoch': 0.05}\n",
            "{'loss': 5.2499, 'learning_rate': 2.331804281345566e-05, 'epoch': 0.05}\n",
            "{'loss': 2.5891, 'learning_rate': 2.3509174311926606e-05, 'epoch': 0.05}\n",
            "{'loss': 1.9099, 'learning_rate': 2.3700305810397554e-05, 'epoch': 0.05}\n",
            "{'loss': 2.2375, 'learning_rate': 2.3891437308868502e-05, 'epoch': 0.05}\n",
            "{'loss': 3.0566, 'learning_rate': 2.408256880733945e-05, 'epoch': 0.05}\n",
            "{'loss': 2.467, 'learning_rate': 2.4273700305810398e-05, 'epoch': 0.05}\n",
            "{'loss': 3.5184, 'learning_rate': 2.4464831804281346e-05, 'epoch': 0.05}\n",
            "{'loss': 4.2107, 'learning_rate': 2.4655963302752294e-05, 'epoch': 0.05}\n",
            "{'loss': 2.5252, 'learning_rate': 2.4847094801223242e-05, 'epoch': 0.05}\n",
            "{'loss': 3.5247, 'learning_rate': 2.503822629969419e-05, 'epoch': 0.05}\n",
            "{'loss': 2.4562, 'learning_rate': 2.5229357798165138e-05, 'epoch': 0.05}\n",
            "{'loss': 2.0517, 'learning_rate': 2.5420489296636086e-05, 'epoch': 0.05}\n",
            "{'loss': 1.5182, 'learning_rate': 2.5611620795107034e-05, 'epoch': 0.05}\n",
            "{'loss': 3.6587, 'learning_rate': 2.5802752293577982e-05, 'epoch': 0.05}\n",
            "{'loss': 0.9357, 'learning_rate': 2.5993883792048927e-05, 'epoch': 0.05}\n",
            "{'loss': 1.5723, 'learning_rate': 2.6185015290519875e-05, 'epoch': 0.05}\n",
            "{'loss': 6.2684, 'learning_rate': 2.6376146788990823e-05, 'epoch': 0.05}\n",
            "{'loss': 4.0478, 'learning_rate': 2.6567278287461778e-05, 'epoch': 0.05}\n",
            "{'loss': 1.8032, 'learning_rate': 2.6758409785932726e-05, 'epoch': 0.05}\n",
            "{'loss': 4.9302, 'learning_rate': 2.6949541284403674e-05, 'epoch': 0.05}\n",
            "{'loss': 4.6556, 'learning_rate': 2.7140672782874622e-05, 'epoch': 0.05}\n",
            "{'loss': 4.9794, 'learning_rate': 2.733180428134557e-05, 'epoch': 0.05}\n",
            "{'loss': 3.0318, 'learning_rate': 2.7522935779816515e-05, 'epoch': 0.06}\n",
            "{'loss': 3.6681, 'learning_rate': 2.7714067278287463e-05, 'epoch': 0.06}\n",
            "{'loss': 3.093, 'learning_rate': 2.790519877675841e-05, 'epoch': 0.06}\n",
            "{'loss': 2.0372, 'learning_rate': 2.809633027522936e-05, 'epoch': 0.06}\n",
            "{'loss': 2.4776, 'learning_rate': 2.8287461773700307e-05, 'epoch': 0.06}\n",
            "{'loss': 4.3074, 'learning_rate': 2.8478593272171255e-05, 'epoch': 0.06}\n",
            "{'loss': 3.0756, 'learning_rate': 2.8669724770642203e-05, 'epoch': 0.06}\n",
            "{'loss': 3.7973, 'learning_rate': 2.886085626911315e-05, 'epoch': 0.06}\n",
            "{'loss': 2.1901, 'learning_rate': 2.90519877675841e-05, 'epoch': 0.06}\n",
            "{'loss': 6.5419, 'learning_rate': 2.9243119266055048e-05, 'epoch': 0.06}\n",
            "{'loss': 5.2315, 'learning_rate': 2.9434250764525996e-05, 'epoch': 0.06}\n",
            "{'loss': 2.377, 'learning_rate': 2.9625382262996944e-05, 'epoch': 0.06}\n",
            "{'loss': 2.5547, 'learning_rate': 2.9816513761467892e-05, 'epoch': 0.06}\n",
            "{'loss': 2.0651, 'learning_rate': 3.0007645259938837e-05, 'epoch': 0.06}\n",
            "{'loss': 2.655, 'learning_rate': 3.0198776758409785e-05, 'epoch': 0.06}\n",
            "{'loss': 1.7337, 'learning_rate': 3.0389908256880733e-05, 'epoch': 0.06}\n",
            "{'loss': 1.3964, 'learning_rate': 3.0581039755351684e-05, 'epoch': 0.06}\n",
            "{'loss': 3.8962, 'learning_rate': 3.077217125382263e-05, 'epoch': 0.06}\n",
            "{'loss': 3.4265, 'learning_rate': 3.096330275229358e-05, 'epoch': 0.06}\n",
            "{'loss': 3.0418, 'learning_rate': 3.1154434250764525e-05, 'epoch': 0.06}\n",
            "{'loss': 2.7293, 'learning_rate': 3.1345565749235476e-05, 'epoch': 0.06}\n",
            "{'loss': 2.2921, 'learning_rate': 3.153669724770643e-05, 'epoch': 0.06}\n",
            "{'loss': 3.2466, 'learning_rate': 3.172782874617737e-05, 'epoch': 0.06}\n",
            "{'loss': 2.71, 'learning_rate': 3.1918960244648324e-05, 'epoch': 0.06}\n",
            "{'loss': 3.1088, 'learning_rate': 3.211009174311927e-05, 'epoch': 0.06}\n",
            "{'loss': 2.4089, 'learning_rate': 3.230122324159022e-05, 'epoch': 0.06}\n",
            "{'loss': 2.2423, 'learning_rate': 3.2492354740061165e-05, 'epoch': 0.06}\n",
            "{'loss': 3.5631, 'learning_rate': 3.268348623853211e-05, 'epoch': 0.07}\n",
            "{'loss': 2.8803, 'learning_rate': 3.287461773700306e-05, 'epoch': 0.07}\n",
            "{'loss': 2.678, 'learning_rate': 3.3065749235474006e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2597, 'learning_rate': 3.325688073394496e-05, 'epoch': 0.07}\n",
            "{'loss': 4.5555, 'learning_rate': 3.34480122324159e-05, 'epoch': 0.07}\n",
            "{'loss': 5.0659, 'learning_rate': 3.363914373088685e-05, 'epoch': 0.07}\n",
            "{'loss': 4.6191, 'learning_rate': 3.38302752293578e-05, 'epoch': 0.07}\n",
            "{'loss': 3.2296, 'learning_rate': 3.402140672782875e-05, 'epoch': 0.07}\n",
            "{'loss': 2.6979, 'learning_rate': 3.4212538226299694e-05, 'epoch': 0.07}\n",
            "{'loss': 2.494, 'learning_rate': 3.4403669724770645e-05, 'epoch': 0.07}\n",
            "{'loss': 6.0883, 'learning_rate': 3.459480122324159e-05, 'epoch': 0.07}\n",
            "{'loss': 4.03, 'learning_rate': 3.478593272171254e-05, 'epoch': 0.07}\n",
            "{'loss': 6.9121, 'learning_rate': 3.4977064220183486e-05, 'epoch': 0.07}\n",
            "{'loss': 3.8806, 'learning_rate': 3.516819571865443e-05, 'epoch': 0.07}\n",
            "{'loss': 2.6496, 'learning_rate': 3.535932721712538e-05, 'epoch': 0.07}\n",
            "{'loss': 3.0137, 'learning_rate': 3.555045871559633e-05, 'epoch': 0.07}\n",
            "{'loss': 2.0978, 'learning_rate': 3.574159021406728e-05, 'epoch': 0.07}\n",
            "{'loss': 2.329, 'learning_rate': 3.593272171253822e-05, 'epoch': 0.07}\n",
            "{'loss': 2.038, 'learning_rate': 3.612385321100918e-05, 'epoch': 0.07}\n",
            "{'loss': 1.1251, 'learning_rate': 3.6314984709480126e-05, 'epoch': 0.07}\n",
            "{'loss': 4.5161, 'learning_rate': 3.650611620795108e-05, 'epoch': 0.07}\n",
            "{'loss': 3.7091, 'learning_rate': 3.669724770642202e-05, 'epoch': 0.07}\n",
            "{'loss': 4.8003, 'learning_rate': 3.688837920489297e-05, 'epoch': 0.07}\n",
            "{'loss': 2.1608, 'learning_rate': 3.707951070336392e-05, 'epoch': 0.07}\n",
            "{'loss': 4.2833, 'learning_rate': 3.727064220183486e-05, 'epoch': 0.07}\n",
            "{'loss': 4.6282, 'learning_rate': 3.7461773700305815e-05, 'epoch': 0.07}\n",
            "{'loss': 3.9277, 'learning_rate': 3.765290519877676e-05, 'epoch': 0.08}\n",
            "{'loss': 3.6486, 'learning_rate': 3.784403669724771e-05, 'epoch': 0.08}\n",
            "{'loss': 5.0727, 'learning_rate': 3.8035168195718655e-05, 'epoch': 0.08}\n",
            "{'loss': 1.601, 'learning_rate': 3.822629969418961e-05, 'epoch': 0.08}\n",
            "{'loss': 2.6095, 'learning_rate': 3.841743119266055e-05, 'epoch': 0.08}\n",
            "{'loss': 6.3234, 'learning_rate': 3.86085626911315e-05, 'epoch': 0.08}\n",
            "{'loss': 4.98, 'learning_rate': 3.879969418960245e-05, 'epoch': 0.08}\n",
            "{'loss': 3.1046, 'learning_rate': 3.89908256880734e-05, 'epoch': 0.08}\n",
            "{'loss': 3.0293, 'learning_rate': 3.9181957186544344e-05, 'epoch': 0.08}\n",
            "{'loss': 2.9984, 'learning_rate': 3.937308868501529e-05, 'epoch': 0.08}\n",
            "{'loss': 3.2568, 'learning_rate': 3.956422018348624e-05, 'epoch': 0.08}\n",
            "{'loss': 1.065, 'learning_rate': 3.9755351681957185e-05, 'epoch': 0.08}\n",
            "{'loss': 1.4361, 'learning_rate': 3.9946483180428136e-05, 'epoch': 0.08}\n",
            "{'loss': 3.861, 'learning_rate': 4.013761467889908e-05, 'epoch': 0.08}\n",
            "{'loss': 3.1528, 'learning_rate': 4.032874617737003e-05, 'epoch': 0.08}\n",
            "{'loss': 4.4475, 'learning_rate': 4.051987767584098e-05, 'epoch': 0.08}\n",
            "{'loss': 4.6897, 'learning_rate': 4.071100917431193e-05, 'epoch': 0.08}\n",
            "{'loss': 4.4293, 'learning_rate': 4.090214067278288e-05, 'epoch': 0.08}\n",
            "{'loss': 3.3354, 'learning_rate': 4.1093272171253824e-05, 'epoch': 0.08}\n",
            "{'loss': 2.0731, 'learning_rate': 4.1284403669724776e-05, 'epoch': 0.08}\n",
            "{'loss': 3.341, 'learning_rate': 4.147553516819572e-05, 'epoch': 0.08}\n",
            "{'loss': 1.9511, 'learning_rate': 4.166666666666667e-05, 'epoch': 0.08}\n",
            "{'loss': 3.0042, 'learning_rate': 4.185779816513762e-05, 'epoch': 0.08}\n",
            "{'loss': 5.3077, 'learning_rate': 4.204892966360857e-05, 'epoch': 0.08}\n",
            "{'loss': 6.7617, 'learning_rate': 4.224006116207951e-05, 'epoch': 0.08}\n",
            "{'loss': 5.3755, 'learning_rate': 4.2431192660550464e-05, 'epoch': 0.08}\n",
            "{'loss': 4.8178, 'learning_rate': 4.262232415902141e-05, 'epoch': 0.09}\n",
            "{'loss': 3.9662, 'learning_rate': 4.281345565749236e-05, 'epoch': 0.09}\n",
            "{'loss': 3.8513, 'learning_rate': 4.3004587155963305e-05, 'epoch': 0.09}\n",
            "{'loss': 4.6952, 'learning_rate': 4.319571865443425e-05, 'epoch': 0.09}\n",
            "{'loss': 4.5285, 'learning_rate': 4.33868501529052e-05, 'epoch': 0.09}\n",
            "{'loss': 4.2752, 'learning_rate': 4.3577981651376146e-05, 'epoch': 0.09}\n",
            "{'loss': 4.4604, 'learning_rate': 4.37691131498471e-05, 'epoch': 0.09}\n",
            "{'loss': 3.5361, 'learning_rate': 4.396024464831804e-05, 'epoch': 0.09}\n",
            "{'loss': 6.5618, 'learning_rate': 4.4151376146788994e-05, 'epoch': 0.09}\n",
            "{'loss': 6.3403, 'learning_rate': 4.434250764525994e-05, 'epoch': 0.09}\n",
            "{'loss': 5.4532, 'learning_rate': 4.453363914373089e-05, 'epoch': 0.09}\n",
            "{'loss': 4.9947, 'learning_rate': 4.4724770642201834e-05, 'epoch': 0.09}\n",
            "{'loss': 4.6186, 'learning_rate': 4.4915902140672786e-05, 'epoch': 0.09}\n",
            "{'loss': 6.6344, 'learning_rate': 4.510703363914373e-05, 'epoch': 0.09}\n",
            "{'loss': 4.4378, 'learning_rate': 4.529816513761468e-05, 'epoch': 0.09}\n",
            "{'loss': 4.753, 'learning_rate': 4.548929663608563e-05, 'epoch': 0.09}\n",
            "{'loss': 3.8402, 'learning_rate': 4.568042813455658e-05, 'epoch': 0.09}\n",
            "{'loss': 3.4658, 'learning_rate': 4.587155963302753e-05, 'epoch': 0.09}\n",
            "{'loss': 7.1605, 'learning_rate': 4.6062691131498474e-05, 'epoch': 0.09}\n",
            "{'loss': 6.2835, 'learning_rate': 4.6253822629969426e-05, 'epoch': 0.09}\n",
            "{'loss': 5.8873, 'learning_rate': 4.644495412844037e-05, 'epoch': 0.09}\n",
            "{'loss': 5.4786, 'learning_rate': 4.663608562691132e-05, 'epoch': 0.09}\n",
            "{'loss': 5.0645, 'learning_rate': 4.6827217125382266e-05, 'epoch': 0.09}\n",
            "{'loss': 4.7938, 'learning_rate': 4.701834862385321e-05, 'epoch': 0.09}\n",
            "{'loss': 4.8901, 'learning_rate': 4.720948012232416e-05, 'epoch': 0.09}\n",
            "{'loss': 4.3509, 'learning_rate': 4.740061162079511e-05, 'epoch': 0.09}\n",
            "{'loss': 4.6734, 'learning_rate': 4.759174311926606e-05, 'epoch': 0.1}\n",
            "{'loss': 6.2252, 'learning_rate': 4.7782874617737003e-05, 'epoch': 0.1}\n",
            "{'loss': 6.4648, 'learning_rate': 4.7974006116207955e-05, 'epoch': 0.1}\n",
            "{'loss': 5.5096, 'learning_rate': 4.81651376146789e-05, 'epoch': 0.1}\n",
            "{'loss': 5.9618, 'learning_rate': 4.835626911314985e-05, 'epoch': 0.1}\n",
            "{'loss': 6.1982, 'learning_rate': 4.8547400611620796e-05, 'epoch': 0.1}\n",
            "{'loss': 4.9264, 'learning_rate': 4.873853211009175e-05, 'epoch': 0.1}\n",
            "{'loss': 5.1712, 'learning_rate': 4.892966360856269e-05, 'epoch': 0.1}\n",
            "{'loss': 4.944, 'learning_rate': 4.912079510703364e-05, 'epoch': 0.1}\n",
            "{'loss': 4.5973, 'learning_rate': 4.931192660550459e-05, 'epoch': 0.1}\n",
            "{'loss': 4.5028, 'learning_rate': 4.950305810397553e-05, 'epoch': 0.1}\n",
            "{'loss': 3.9471, 'learning_rate': 4.9694189602446484e-05, 'epoch': 0.1}\n",
            "{'loss': 5.6889, 'learning_rate': 4.988532110091743e-05, 'epoch': 0.1}\n",
            "{'loss': 5.8715, 'learning_rate': 5.007645259938838e-05, 'epoch': 0.1}\n",
            "{'loss': 5.6538, 'learning_rate': 5.026758409785933e-05, 'epoch': 0.1}\n",
            "{'loss': 5.4411, 'learning_rate': 5.0458715596330276e-05, 'epoch': 0.1}\n",
            "{'loss': 4.676, 'learning_rate': 5.064984709480123e-05, 'epoch': 0.1}\n",
            "{'loss': 4.7828, 'learning_rate': 5.084097859327217e-05, 'epoch': 0.1}\n",
            "{'loss': 4.7274, 'learning_rate': 5.1032110091743124e-05, 'epoch': 0.1}\n",
            "{'loss': 5.789, 'learning_rate': 5.122324159021407e-05, 'epoch': 0.1}\n",
            "{'loss': 4.5932, 'learning_rate': 5.141437308868502e-05, 'epoch': 0.1}\n",
            "{'loss': 3.7671, 'learning_rate': 5.1605504587155965e-05, 'epoch': 0.1}\n",
            "{'loss': 6.0445, 'learning_rate': 5.1796636085626916e-05, 'epoch': 0.1}\n",
            "{'loss': 7.0351, 'learning_rate': 5.1987767584097854e-05, 'epoch': 0.1}\n",
            "{'loss': 5.3877, 'learning_rate': 5.217889908256881e-05, 'epoch': 0.1}\n",
            "{'loss': 5.2175, 'learning_rate': 5.237003058103975e-05, 'epoch': 0.1}\n",
            "{'loss': 4.996, 'learning_rate': 5.256116207951071e-05, 'epoch': 0.11}\n",
            "{'loss': 4.6715, 'learning_rate': 5.2752293577981646e-05, 'epoch': 0.11}\n",
            "{'loss': 4.6554, 'learning_rate': 5.2943425076452605e-05, 'epoch': 0.11}\n",
            "{'loss': 4.5556, 'learning_rate': 5.3134556574923556e-05, 'epoch': 0.11}\n",
            "{'loss': 4.1468, 'learning_rate': 5.33256880733945e-05, 'epoch': 0.11}\n",
            "{'loss': 3.7497, 'learning_rate': 5.351681957186545e-05, 'epoch': 0.11}\n",
            "{'loss': 6.0998, 'learning_rate': 5.370795107033639e-05, 'epoch': 0.11}\n",
            "{'loss': 5.7756, 'learning_rate': 5.389908256880735e-05, 'epoch': 0.11}\n",
            "{'loss': 5.4466, 'learning_rate': 5.4090214067278286e-05, 'epoch': 0.11}\n",
            "{'loss': 5.2856, 'learning_rate': 5.4281345565749245e-05, 'epoch': 0.11}\n",
            "{'loss': 5.0153, 'learning_rate': 5.447247706422018e-05, 'epoch': 0.11}\n",
            "{'loss': 4.8334, 'learning_rate': 5.466360856269114e-05, 'epoch': 0.11}\n",
            "{'loss': 4.5091, 'learning_rate': 5.485474006116208e-05, 'epoch': 0.11}\n",
            "{'loss': 4.2412, 'learning_rate': 5.504587155963303e-05, 'epoch': 0.11}\n",
            "{'loss': 3.8669, 'learning_rate': 5.5237003058103975e-05, 'epoch': 0.11}\n",
            "{'loss': 3.2079, 'learning_rate': 5.5428134556574926e-05, 'epoch': 0.11}\n",
            "{'loss': 6.7703, 'learning_rate': 5.561926605504587e-05, 'epoch': 0.11}\n",
            "{'loss': 5.3279, 'learning_rate': 5.581039755351682e-05, 'epoch': 0.11}\n",
            "{'loss': 7.1302, 'learning_rate': 5.600152905198777e-05, 'epoch': 0.11}\n",
            "{'loss': 4.8669, 'learning_rate': 5.619266055045872e-05, 'epoch': 0.11}\n",
            "{'loss': 5.2399, 'learning_rate': 5.638379204892966e-05, 'epoch': 0.11}\n",
            "{'loss': 5.5394, 'learning_rate': 5.6574923547400615e-05, 'epoch': 0.11}\n",
            "{'loss': 5.6114, 'learning_rate': 5.676605504587156e-05, 'epoch': 0.11}\n",
            "{'loss': 4.022, 'learning_rate': 5.695718654434251e-05, 'epoch': 0.11}\n",
            "{'loss': 4.136, 'learning_rate': 5.7148318042813455e-05, 'epoch': 0.11}\n",
            "{'loss': 3.2232, 'learning_rate': 5.733944954128441e-05, 'epoch': 0.11}\n",
            "{'loss': 5.6785, 'learning_rate': 5.753058103975535e-05, 'epoch': 0.12}\n",
            "{'loss': 6.313, 'learning_rate': 5.77217125382263e-05, 'epoch': 0.12}\n",
            "{'loss': 5.7636, 'learning_rate': 5.7912844036697254e-05, 'epoch': 0.12}\n",
            "{'loss': 6.4527, 'learning_rate': 5.81039755351682e-05, 'epoch': 0.12}\n",
            "{'loss': 4.9578, 'learning_rate': 5.829510703363915e-05, 'epoch': 0.12}\n",
            "{'loss': 4.892, 'learning_rate': 5.8486238532110095e-05, 'epoch': 0.12}\n",
            "{'loss': 4.8081, 'learning_rate': 5.867737003058105e-05, 'epoch': 0.12}\n",
            "{'loss': 4.4808, 'learning_rate': 5.886850152905199e-05, 'epoch': 0.12}\n",
            "{'loss': 4.7131, 'learning_rate': 5.905963302752294e-05, 'epoch': 0.12}\n",
            "{'loss': 3.8551, 'learning_rate': 5.925076452599389e-05, 'epoch': 0.12}\n",
            "{'loss': 6.2341, 'learning_rate': 5.944189602446484e-05, 'epoch': 0.12}\n",
            "{'loss': 5.5244, 'learning_rate': 5.9633027522935784e-05, 'epoch': 0.12}\n",
            "{'loss': 5.7357, 'learning_rate': 5.9824159021406735e-05, 'epoch': 0.12}\n",
            "{'loss': 5.4467, 'learning_rate': 6.001529051987767e-05, 'epoch': 0.12}\n",
            "{'loss': 5.4345, 'learning_rate': 6.020642201834863e-05, 'epoch': 0.12}\n",
            "{'loss': 5.6517, 'learning_rate': 6.039755351681957e-05, 'epoch': 0.12}\n",
            "{'loss': 4.6194, 'learning_rate': 6.058868501529053e-05, 'epoch': 0.12}\n",
            "{'loss': 4.892, 'learning_rate': 6.0779816513761465e-05, 'epoch': 0.12}\n",
            "{'loss': 4.5724, 'learning_rate': 6.0970948012232424e-05, 'epoch': 0.12}\n",
            "{'loss': 4.0004, 'learning_rate': 6.116207951070337e-05, 'epoch': 0.12}\n",
            "{'loss': 5.674, 'learning_rate': 6.135321100917432e-05, 'epoch': 0.12}\n",
            "{'loss': 5.9126, 'learning_rate': 6.154434250764526e-05, 'epoch': 0.12}\n",
            "{'loss': 5.6376, 'learning_rate': 6.173547400611621e-05, 'epoch': 0.12}\n",
            "{'loss': 6.4409, 'learning_rate': 6.192660550458716e-05, 'epoch': 0.12}\n",
            "{'loss': 5.7721, 'learning_rate': 6.211773700305811e-05, 'epoch': 0.12}\n",
            "{'loss': 5.1021, 'learning_rate': 6.230886850152905e-05, 'epoch': 0.12}\n",
            "{'loss': 5.1267, 'learning_rate': 6.25e-05, 'epoch': 0.13}\n",
            "{'loss': 4.6386, 'learning_rate': 6.269113149847095e-05, 'epoch': 0.13}\n",
            "{'loss': 4.3987, 'learning_rate': 6.28822629969419e-05, 'epoch': 0.13}\n",
            "{'loss': 3.6924, 'learning_rate': 6.307339449541286e-05, 'epoch': 0.13}\n",
            "{'loss': 5.7924, 'learning_rate': 6.32645259938838e-05, 'epoch': 0.13}\n",
            "{'loss': 6.2774, 'learning_rate': 6.345565749235475e-05, 'epoch': 0.13}\n",
            "{'loss': 5.4663, 'learning_rate': 6.36467889908257e-05, 'epoch': 0.13}\n",
            "{'loss': 5.1378, 'learning_rate': 6.383792048929665e-05, 'epoch': 0.13}\n",
            "{'loss': 4.7527, 'learning_rate': 6.402905198776759e-05, 'epoch': 0.13}\n",
            "{'loss': 4.5259, 'learning_rate': 6.422018348623854e-05, 'epoch': 0.13}\n",
            "{'loss': 4.6762, 'learning_rate': 6.441131498470948e-05, 'epoch': 0.13}\n",
            "{'loss': 4.6969, 'learning_rate': 6.460244648318044e-05, 'epoch': 0.13}\n",
            "{'loss': 4.056, 'learning_rate': 6.479357798165138e-05, 'epoch': 0.13}\n",
            "{'loss': 3.366, 'learning_rate': 6.498470948012233e-05, 'epoch': 0.13}\n",
            "{'loss': 5.9578, 'learning_rate': 6.517584097859327e-05, 'epoch': 0.13}\n",
            "{'loss': 6.1893, 'learning_rate': 6.536697247706422e-05, 'epoch': 0.13}\n",
            "{'loss': 5.2378, 'learning_rate': 6.555810397553517e-05, 'epoch': 0.13}\n",
            "{'loss': 5.4608, 'learning_rate': 6.574923547400612e-05, 'epoch': 0.13}\n",
            "{'loss': 5.6692, 'learning_rate': 6.594036697247706e-05, 'epoch': 0.13}\n",
            "{'loss': 4.6135, 'learning_rate': 6.613149847094801e-05, 'epoch': 0.13}\n",
            "{'loss': 5.342, 'learning_rate': 6.632262996941896e-05, 'epoch': 0.13}\n",
            "{'loss': 4.5053, 'learning_rate': 6.651376146788991e-05, 'epoch': 0.13}\n",
            "{'loss': 3.7674, 'learning_rate': 6.670489296636085e-05, 'epoch': 0.13}\n",
            "{'loss': 3.1864, 'learning_rate': 6.68960244648318e-05, 'epoch': 0.13}\n",
            "{'loss': 5.8796, 'learning_rate': 6.708715596330275e-05, 'epoch': 0.13}\n",
            "{'loss': 6.4451, 'learning_rate': 6.72782874617737e-05, 'epoch': 0.13}\n",
            "{'loss': 6.3187, 'learning_rate': 6.746941896024466e-05, 'epoch': 0.13}\n",
            "{'loss': 5.8588, 'learning_rate': 6.76605504587156e-05, 'epoch': 0.14}\n",
            "{'loss': 5.2056, 'learning_rate': 6.785168195718655e-05, 'epoch': 0.14}\n",
            "{'loss': 6.0835, 'learning_rate': 6.80428134556575e-05, 'epoch': 0.14}\n",
            "{'loss': 4.6722, 'learning_rate': 6.823394495412845e-05, 'epoch': 0.14}\n",
            "{'loss': 4.7542, 'learning_rate': 6.842507645259939e-05, 'epoch': 0.14}\n",
            "{'loss': 4.9168, 'learning_rate': 6.861620795107034e-05, 'epoch': 0.14}\n",
            "{'loss': 3.6511, 'learning_rate': 6.880733944954129e-05, 'epoch': 0.14}\n",
            "{'loss': 5.8349, 'learning_rate': 6.899847094801224e-05, 'epoch': 0.14}\n",
            "{'loss': 5.5996, 'learning_rate': 6.918960244648318e-05, 'epoch': 0.14}\n",
            "{'loss': 5.5303, 'learning_rate': 6.938073394495413e-05, 'epoch': 0.14}\n",
            "{'loss': 5.7279, 'learning_rate': 6.957186544342508e-05, 'epoch': 0.14}\n",
            "{'loss': 5.5485, 'learning_rate': 6.976299694189603e-05, 'epoch': 0.14}\n",
            "{'loss': 5.1498, 'learning_rate': 6.995412844036697e-05, 'epoch': 0.14}\n",
            "{'loss': 5.0103, 'learning_rate': 7.014525993883792e-05, 'epoch': 0.14}\n",
            "{'loss': 4.6626, 'learning_rate': 7.033639143730886e-05, 'epoch': 0.14}\n",
            "{'loss': 5.0658, 'learning_rate': 7.052752293577983e-05, 'epoch': 0.14}\n",
            "{'loss': 4.2332, 'learning_rate': 7.071865443425076e-05, 'epoch': 0.14}\n",
            "{'loss': 6.4277, 'learning_rate': 7.090978593272172e-05, 'epoch': 0.14}\n",
            "{'loss': 5.4687, 'learning_rate': 7.110091743119265e-05, 'epoch': 0.14}\n",
            "{'loss': 5.4217, 'learning_rate': 7.129204892966362e-05, 'epoch': 0.14}\n",
            "{'loss': 5.3313, 'learning_rate': 7.148318042813456e-05, 'epoch': 0.14}\n",
            "{'loss': 5.0846, 'learning_rate': 7.167431192660551e-05, 'epoch': 0.14}\n",
            "{'loss': 4.8954, 'learning_rate': 7.186544342507645e-05, 'epoch': 0.14}\n",
            "{'loss': 4.5661, 'learning_rate': 7.20565749235474e-05, 'epoch': 0.14}\n",
            "{'loss': 4.9983, 'learning_rate': 7.224770642201836e-05, 'epoch': 0.14}\n",
            "{'loss': 4.4208, 'learning_rate': 7.24388379204893e-05, 'epoch': 0.14}\n",
            "{'loss': 4.005, 'learning_rate': 7.262996941896025e-05, 'epoch': 0.15}\n",
            "{'loss': 5.4681, 'learning_rate': 7.282110091743119e-05, 'epoch': 0.15}\n",
            "{'loss': 6.7877, 'learning_rate': 7.301223241590216e-05, 'epoch': 0.15}\n",
            "{'loss': 5.781, 'learning_rate': 7.320336391437309e-05, 'epoch': 0.15}\n",
            "{'loss': 5.4068, 'learning_rate': 7.339449541284404e-05, 'epoch': 0.15}\n",
            "{'loss': 6.0106, 'learning_rate': 7.358562691131498e-05, 'epoch': 0.15}\n",
            "{'loss': 5.6066, 'learning_rate': 7.377675840978593e-05, 'epoch': 0.15}\n",
            "{'loss': 4.5233, 'learning_rate': 7.396788990825689e-05, 'epoch': 0.15}\n",
            "{'loss': 4.5233, 'learning_rate': 7.415902140672784e-05, 'epoch': 0.15}\n",
            "{'loss': 3.9683, 'learning_rate': 7.435015290519877e-05, 'epoch': 0.15}\n",
            "{'loss': 3.7708, 'learning_rate': 7.454128440366973e-05, 'epoch': 0.15}\n",
            "{'loss': 8.2655, 'learning_rate': 7.473241590214068e-05, 'epoch': 0.15}\n",
            "{'loss': 6.1781, 'learning_rate': 7.492354740061163e-05, 'epoch': 0.15}\n",
            "{'loss': 4.9401, 'learning_rate': 7.511467889908257e-05, 'epoch': 0.15}\n",
            "{'loss': 4.769, 'learning_rate': 7.530581039755352e-05, 'epoch': 0.15}\n",
            "{'loss': 4.6929, 'learning_rate': 7.549694189602447e-05, 'epoch': 0.15}\n",
            "{'loss': 4.5881, 'learning_rate': 7.568807339449542e-05, 'epoch': 0.15}\n",
            "{'loss': 4.6096, 'learning_rate': 7.587920489296636e-05, 'epoch': 0.15}\n",
            "{'loss': 4.1727, 'learning_rate': 7.607033639143731e-05, 'epoch': 0.15}\n",
            "{'loss': 3.9176, 'learning_rate': 7.626146788990826e-05, 'epoch': 0.15}\n",
            "{'loss': 3.4282, 'learning_rate': 7.645259938837921e-05, 'epoch': 0.15}\n",
            "{'loss': 5.8682, 'learning_rate': 7.664373088685015e-05, 'epoch': 0.15}\n",
            "{'loss': 6.08, 'learning_rate': 7.68348623853211e-05, 'epoch': 0.15}\n",
            "{'loss': 6.0012, 'learning_rate': 7.702599388379205e-05, 'epoch': 0.15}\n",
            "{'loss': 6.8625, 'learning_rate': 7.7217125382263e-05, 'epoch': 0.15}\n",
            "{'loss': 6.3053, 'learning_rate': 7.740825688073396e-05, 'epoch': 0.15}\n",
            "{'loss': 5.2096, 'learning_rate': 7.75993883792049e-05, 'epoch': 0.16}\n",
            "{'loss': 4.6273, 'learning_rate': 7.779051987767585e-05, 'epoch': 0.16}\n",
            "{'loss': 4.2487, 'learning_rate': 7.79816513761468e-05, 'epoch': 0.16}\n",
            "{'loss': 4.2471, 'learning_rate': 7.817278287461775e-05, 'epoch': 0.16}\n",
            "{'loss': 3.1827, 'learning_rate': 7.836391437308869e-05, 'epoch': 0.16}\n",
            "{'loss': 5.7481, 'learning_rate': 7.855504587155964e-05, 'epoch': 0.16}\n",
            "{'loss': 5.8574, 'learning_rate': 7.874617737003058e-05, 'epoch': 0.16}\n",
            "{'loss': 6.0993, 'learning_rate': 7.893730886850154e-05, 'epoch': 0.16}\n",
            "{'loss': 5.1637, 'learning_rate': 7.912844036697248e-05, 'epoch': 0.16}\n",
            "{'loss': 5.8856, 'learning_rate': 7.931957186544343e-05, 'epoch': 0.16}\n",
            "{'loss': 4.5578, 'learning_rate': 7.951070336391437e-05, 'epoch': 0.16}\n",
            "{'loss': 4.6699, 'learning_rate': 7.970183486238532e-05, 'epoch': 0.16}\n",
            "{'loss': 4.8256, 'learning_rate': 7.989296636085627e-05, 'epoch': 0.16}\n",
            "{'loss': 3.9483, 'learning_rate': 8.008409785932722e-05, 'epoch': 0.16}\n",
            "{'loss': 3.3115, 'learning_rate': 8.027522935779816e-05, 'epoch': 0.16}\n",
            "{'loss': 6.7046, 'learning_rate': 8.046636085626911e-05, 'epoch': 0.16}\n",
            "{'loss': 6.0963, 'learning_rate': 8.065749235474006e-05, 'epoch': 0.16}\n",
            "{'loss': 5.3328, 'learning_rate': 8.084862385321102e-05, 'epoch': 0.16}\n",
            "{'loss': 6.1924, 'learning_rate': 8.103975535168195e-05, 'epoch': 0.16}\n",
            "{'loss': 4.98, 'learning_rate': 8.12308868501529e-05, 'epoch': 0.16}\n",
            "{'loss': 4.971, 'learning_rate': 8.142201834862386e-05, 'epoch': 0.16}\n",
            "{'loss': 5.0417, 'learning_rate': 8.161314984709481e-05, 'epoch': 0.16}\n",
            "{'loss': 4.0152, 'learning_rate': 8.180428134556576e-05, 'epoch': 0.16}\n",
            "{'loss': 4.2734, 'learning_rate': 8.19954128440367e-05, 'epoch': 0.16}\n",
            "{'loss': 3.5619, 'learning_rate': 8.218654434250765e-05, 'epoch': 0.16}\n",
            "{'loss': 6.1495, 'learning_rate': 8.23776758409786e-05, 'epoch': 0.16}\n",
            "{'loss': 6.1944, 'learning_rate': 8.256880733944955e-05, 'epoch': 0.17}\n",
            "{'loss': 6.2107, 'learning_rate': 8.275993883792049e-05, 'epoch': 0.17}\n",
            "{'loss': 6.0482, 'learning_rate': 8.295107033639144e-05, 'epoch': 0.17}\n",
            "{'loss': 5.5792, 'learning_rate': 8.314220183486239e-05, 'epoch': 0.17}\n",
            "{'loss': 4.5302, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.17}\n",
            "{'loss': 4.8744, 'learning_rate': 8.352446483180428e-05, 'epoch': 0.17}\n",
            "{'loss': 4.5283, 'learning_rate': 8.371559633027523e-05, 'epoch': 0.17}\n",
            "{'loss': 3.964, 'learning_rate': 8.390672782874618e-05, 'epoch': 0.17}\n",
            "{'loss': 3.4031, 'learning_rate': 8.409785932721714e-05, 'epoch': 0.17}\n",
            "{'loss': 5.8963, 'learning_rate': 8.428899082568807e-05, 'epoch': 0.17}\n",
            "{'loss': 5.7671, 'learning_rate': 8.448012232415903e-05, 'epoch': 0.17}\n",
            "{'loss': 5.4815, 'learning_rate': 8.467125382262996e-05, 'epoch': 0.17}\n",
            "{'loss': 5.4045, 'learning_rate': 8.486238532110093e-05, 'epoch': 0.17}\n",
            "{'loss': 4.9685, 'learning_rate': 8.505351681957187e-05, 'epoch': 0.17}\n",
            "{'loss': 5.0438, 'learning_rate': 8.524464831804282e-05, 'epoch': 0.17}\n",
            "{'loss': 4.7098, 'learning_rate': 8.543577981651376e-05, 'epoch': 0.17}\n",
            "{'loss': 4.4434, 'learning_rate': 8.562691131498472e-05, 'epoch': 0.17}\n",
            "{'loss': 4.0439, 'learning_rate': 8.581804281345566e-05, 'epoch': 0.17}\n",
            "{'loss': 3.3117, 'learning_rate': 8.600917431192661e-05, 'epoch': 0.17}\n",
            "{'loss': 6.0867, 'learning_rate': 8.620030581039755e-05, 'epoch': 0.17}\n",
            "{'loss': 5.5259, 'learning_rate': 8.63914373088685e-05, 'epoch': 0.17}\n",
            "{'loss': 7.4121, 'learning_rate': 8.658256880733946e-05, 'epoch': 0.17}\n",
            "{'loss': 5.2458, 'learning_rate': 8.67737003058104e-05, 'epoch': 0.17}\n",
            "{'loss': 5.2531, 'learning_rate': 8.696483180428135e-05, 'epoch': 0.17}\n",
            "{'loss': 5.2395, 'learning_rate': 8.715596330275229e-05, 'epoch': 0.17}\n",
            "{'loss': 5.3337, 'learning_rate': 8.734709480122326e-05, 'epoch': 0.17}\n",
            "{'loss': 5.6458, 'learning_rate': 8.75382262996942e-05, 'epoch': 0.18}\n",
            "{'loss': 4.4315, 'learning_rate': 8.772935779816515e-05, 'epoch': 0.18}\n",
            "{'loss': 3.65, 'learning_rate': 8.792048929663608e-05, 'epoch': 0.18}\n",
            "{'loss': 5.7498, 'learning_rate': 8.811162079510704e-05, 'epoch': 0.18}\n",
            "{'loss': 5.7035, 'learning_rate': 8.830275229357799e-05, 'epoch': 0.18}\n",
            "{'loss': 5.9294, 'learning_rate': 8.849388379204894e-05, 'epoch': 0.18}\n",
            "{'loss': 6.5504, 'learning_rate': 8.868501529051988e-05, 'epoch': 0.18}\n",
            "{'loss': 6.7571, 'learning_rate': 8.887614678899083e-05, 'epoch': 0.18}\n",
            "{'loss': 5.2504, 'learning_rate': 8.906727828746178e-05, 'epoch': 0.18}\n",
            "{'loss': 5.425, 'learning_rate': 8.925840978593273e-05, 'epoch': 0.18}\n",
            "{'loss': 4.6067, 'learning_rate': 8.944954128440367e-05, 'epoch': 0.18}\n",
            "{'loss': 4.0387, 'learning_rate': 8.964067278287462e-05, 'epoch': 0.18}\n",
            "{'loss': 3.3168, 'learning_rate': 8.983180428134557e-05, 'epoch': 0.18}\n",
            "{'loss': 6.3202, 'learning_rate': 9.002293577981652e-05, 'epoch': 0.18}\n",
            "{'loss': 5.7147, 'learning_rate': 9.021406727828746e-05, 'epoch': 0.18}\n",
            "{'loss': 5.4226, 'learning_rate': 9.040519877675841e-05, 'epoch': 0.18}\n",
            "{'loss': 5.2918, 'learning_rate': 9.059633027522936e-05, 'epoch': 0.18}\n",
            "{'loss': 4.8478, 'learning_rate': 9.078746177370032e-05, 'epoch': 0.18}\n",
            "{'loss': 4.7826, 'learning_rate': 9.097859327217125e-05, 'epoch': 0.18}\n",
            "{'loss': 4.8554, 'learning_rate': 9.11697247706422e-05, 'epoch': 0.18}\n",
            "{'loss': 4.5636, 'learning_rate': 9.136085626911316e-05, 'epoch': 0.18}\n",
            "{'loss': 4.233, 'learning_rate': 9.155198776758411e-05, 'epoch': 0.18}\n",
            "{'loss': 3.9599, 'learning_rate': 9.174311926605506e-05, 'epoch': 0.18}\n",
            "{'loss': 5.6175, 'learning_rate': 9.1934250764526e-05, 'epoch': 0.18}\n",
            "{'loss': 6.3466, 'learning_rate': 9.212538226299695e-05, 'epoch': 0.18}\n",
            "{'loss': 5.7826, 'learning_rate': 9.23165137614679e-05, 'epoch': 0.18}\n",
            "{'loss': 5.2276, 'learning_rate': 9.250764525993885e-05, 'epoch': 0.19}\n",
            "{'loss': 5.1824, 'learning_rate': 9.269877675840979e-05, 'epoch': 0.19}\n",
            "{'loss': 5.3842, 'learning_rate': 9.288990825688074e-05, 'epoch': 0.19}\n",
            "{'loss': 4.5367, 'learning_rate': 9.308103975535168e-05, 'epoch': 0.19}\n",
            "{'loss': 5.0198, 'learning_rate': 9.327217125382264e-05, 'epoch': 0.19}\n",
            "{'loss': 4.5024, 'learning_rate': 9.346330275229358e-05, 'epoch': 0.19}\n",
            "{'loss': 3.5671, 'learning_rate': 9.365443425076453e-05, 'epoch': 0.19}\n",
            "{'loss': 5.7776, 'learning_rate': 9.384556574923547e-05, 'epoch': 0.19}\n",
            "{'loss': 5.6548, 'learning_rate': 9.403669724770642e-05, 'epoch': 0.19}\n",
            "{'loss': 5.3211, 'learning_rate': 9.422782874617737e-05, 'epoch': 0.19}\n",
            "{'loss': 5.2226, 'learning_rate': 9.441896024464833e-05, 'epoch': 0.19}\n",
            "{'loss': 4.7624, 'learning_rate': 9.461009174311926e-05, 'epoch': 0.19}\n",
            "{'loss': 4.5014, 'learning_rate': 9.480122324159021e-05, 'epoch': 0.19}\n",
            "{'loss': 4.3936, 'learning_rate': 9.499235474006117e-05, 'epoch': 0.19}\n",
            "{'loss': 4.4591, 'learning_rate': 9.518348623853212e-05, 'epoch': 0.19}\n",
            "{'loss': 4.541, 'learning_rate': 9.537461773700306e-05, 'epoch': 0.19}\n",
            "{'loss': 4.0756, 'learning_rate': 9.556574923547401e-05, 'epoch': 0.19}\n",
            "{'loss': 5.7363, 'learning_rate': 9.575688073394496e-05, 'epoch': 0.19}\n",
            "{'loss': 5.7416, 'learning_rate': 9.594801223241591e-05, 'epoch': 0.19}\n",
            "{'loss': 5.5543, 'learning_rate': 9.613914373088685e-05, 'epoch': 0.19}\n",
            "{'loss': 6.2195, 'learning_rate': 9.63302752293578e-05, 'epoch': 0.19}\n",
            "{'loss': 5.7495, 'learning_rate': 9.652140672782875e-05, 'epoch': 0.19}\n",
            "{'loss': 5.9254, 'learning_rate': 9.67125382262997e-05, 'epoch': 0.19}\n",
            "{'loss': 4.9299, 'learning_rate': 9.690366972477065e-05, 'epoch': 0.19}\n",
            "{'loss': 4.5427, 'learning_rate': 9.709480122324159e-05, 'epoch': 0.19}\n",
            "{'loss': 3.6645, 'learning_rate': 9.728593272171254e-05, 'epoch': 0.19}\n",
            "{'loss': 3.0091, 'learning_rate': 9.74770642201835e-05, 'epoch': 0.19}\n",
            "{'loss': 6.065, 'learning_rate': 9.766819571865445e-05, 'epoch': 0.2}\n",
            "{'loss': 6.4553, 'learning_rate': 9.785932721712538e-05, 'epoch': 0.2}\n",
            "{'loss': 5.8125, 'learning_rate': 9.805045871559634e-05, 'epoch': 0.2}\n",
            "{'loss': 5.1966, 'learning_rate': 9.824159021406729e-05, 'epoch': 0.2}\n",
            "{'loss': 4.957, 'learning_rate': 9.843272171253824e-05, 'epoch': 0.2}\n",
            "{'loss': 4.6279, 'learning_rate': 9.862385321100918e-05, 'epoch': 0.2}\n",
            "{'loss': 4.7371, 'learning_rate': 9.881498470948013e-05, 'epoch': 0.2}\n",
            "{'loss': 4.1597, 'learning_rate': 9.900611620795107e-05, 'epoch': 0.2}\n",
            "{'loss': 4.2552, 'learning_rate': 9.919724770642203e-05, 'epoch': 0.2}\n",
            "{'loss': 3.3876, 'learning_rate': 9.938837920489297e-05, 'epoch': 0.2}\n",
            "{'loss': 5.8194, 'learning_rate': 9.957951070336392e-05, 'epoch': 0.2}\n",
            "{'loss': 6.1385, 'learning_rate': 9.977064220183486e-05, 'epoch': 0.2}\n",
            "{'loss': 5.386, 'learning_rate': 9.996177370030582e-05, 'epoch': 0.2}\n",
            "{'loss': 5.6657, 'learning_rate': 9.999195106245977e-05, 'epoch': 0.2}\n",
            "{'loss': 6.1565, 'learning_rate': 9.998188989053445e-05, 'epoch': 0.2}\n",
            "{'loss': 4.9315, 'learning_rate': 9.997182871860915e-05, 'epoch': 0.2}\n",
            "{'loss': 4.4615, 'learning_rate': 9.996176754668383e-05, 'epoch': 0.2}\n",
            "{'loss': 4.268, 'learning_rate': 9.995170637475854e-05, 'epoch': 0.2}\n",
            "{'loss': 4.2139, 'learning_rate': 9.994164520283323e-05, 'epoch': 0.2}\n",
            "{'loss': 3.4391, 'learning_rate': 9.993158403090792e-05, 'epoch': 0.2}\n",
            "{'loss': 6.0361, 'learning_rate': 9.992152285898261e-05, 'epoch': 0.2}\n",
            "{'loss': 5.9954, 'learning_rate': 9.991146168705732e-05, 'epoch': 0.2}\n",
            "{'loss': 5.5395, 'learning_rate': 9.990140051513201e-05, 'epoch': 0.2}\n",
            "{'loss': 5.9566, 'learning_rate': 9.98913393432067e-05, 'epoch': 0.2}\n",
            "{'loss': 5.6516, 'learning_rate': 9.988127817128141e-05, 'epoch': 0.2}\n",
            "{'loss': 4.9349, 'learning_rate': 9.987121699935609e-05, 'epoch': 0.2}\n",
            "{'loss': 5.0688, 'learning_rate': 9.986115582743079e-05, 'epoch': 0.21}\n",
            "{'loss': 4.8554, 'learning_rate': 9.985109465550547e-05, 'epoch': 0.21}\n",
            "{'loss': 4.2537, 'learning_rate': 9.984103348358017e-05, 'epoch': 0.21}\n",
            "{'loss': 3.9726, 'learning_rate': 9.983097231165487e-05, 'epoch': 0.21}\n",
            "{'loss': 6.2365, 'learning_rate': 9.982091113972956e-05, 'epoch': 0.21}\n",
            "{'loss': 6.0113, 'learning_rate': 9.981084996780425e-05, 'epoch': 0.21}\n",
            "{'loss': 5.3505, 'learning_rate': 9.980078879587896e-05, 'epoch': 0.21}\n",
            "{'loss': 5.1959, 'learning_rate': 9.979072762395363e-05, 'epoch': 0.21}\n",
            "{'loss': 5.272, 'learning_rate': 9.978066645202834e-05, 'epoch': 0.21}\n",
            "{'loss': 4.9712, 'learning_rate': 9.977060528010303e-05, 'epoch': 0.21}\n",
            "{'loss': 5.2798, 'learning_rate': 9.976054410817772e-05, 'epoch': 0.21}\n",
            "{'loss': 4.9643, 'learning_rate': 9.975048293625242e-05, 'epoch': 0.21}\n",
            "{'loss': 3.8882, 'learning_rate': 9.974042176432712e-05, 'epoch': 0.21}\n",
            "{'loss': 3.9841, 'learning_rate': 9.97303605924018e-05, 'epoch': 0.21}\n",
            "{'loss': 6.0405, 'learning_rate': 9.97202994204765e-05, 'epoch': 0.21}\n",
            "{'loss': 5.966, 'learning_rate': 9.97102382485512e-05, 'epoch': 0.21}\n",
            "{'loss': 5.4878, 'learning_rate': 9.970017707662589e-05, 'epoch': 0.21}\n",
            "{'loss': 5.2255, 'learning_rate': 9.969011590470058e-05, 'epoch': 0.21}\n",
            "{'loss': 4.6549, 'learning_rate': 9.968005473277527e-05, 'epoch': 0.21}\n",
            "{'loss': 4.5404, 'learning_rate': 9.966999356084998e-05, 'epoch': 0.21}\n",
            "{'loss': 4.5141, 'learning_rate': 9.965993238892467e-05, 'epoch': 0.21}\n",
            "{'loss': 4.4185, 'learning_rate': 9.964987121699936e-05, 'epoch': 0.21}\n",
            "{'loss': 4.8284, 'learning_rate': 9.963981004507405e-05, 'epoch': 0.21}\n",
            "{'loss': 3.5565, 'learning_rate': 9.962974887314876e-05, 'epoch': 0.21}\n",
            "{'loss': 6.0455, 'learning_rate': 9.961968770122344e-05, 'epoch': 0.21}\n",
            "{'loss': 5.6118, 'learning_rate': 9.960962652929814e-05, 'epoch': 0.21}\n",
            "{'loss': 5.5764, 'learning_rate': 9.959956535737282e-05, 'epoch': 0.22}\n",
            "{'loss': 6.4098, 'learning_rate': 9.958950418544753e-05, 'epoch': 0.22}\n",
            "{'loss': 5.1823, 'learning_rate': 9.957944301352222e-05, 'epoch': 0.22}\n",
            "{'loss': 5.6871, 'learning_rate': 9.956938184159691e-05, 'epoch': 0.22}\n",
            "{'loss': 5.2964, 'learning_rate': 9.95593206696716e-05, 'epoch': 0.22}\n",
            "{'loss': 4.6095, 'learning_rate': 9.954925949774631e-05, 'epoch': 0.22}\n",
            "{'loss': 4.2564, 'learning_rate': 9.953919832582099e-05, 'epoch': 0.22}\n",
            "{'loss': 3.863, 'learning_rate': 9.952913715389569e-05, 'epoch': 0.22}\n",
            "{'loss': 5.6901, 'learning_rate': 9.951907598197038e-05, 'epoch': 0.22}\n",
            "{'loss': 5.6852, 'learning_rate': 9.950901481004508e-05, 'epoch': 0.22}\n",
            "{'loss': 6.1241, 'learning_rate': 9.949895363811977e-05, 'epoch': 0.22}\n",
            "{'loss': 5.1088, 'learning_rate': 9.948889246619447e-05, 'epoch': 0.22}\n",
            "{'loss': 4.7606, 'learning_rate': 9.947883129426916e-05, 'epoch': 0.22}\n",
            "{'loss': 4.7416, 'learning_rate': 9.946877012234386e-05, 'epoch': 0.22}\n",
            "{'loss': 4.5118, 'learning_rate': 9.945870895041855e-05, 'epoch': 0.22}\n",
            "{'loss': 4.3609, 'learning_rate': 9.944864777849324e-05, 'epoch': 0.22}\n",
            "{'loss': 4.0993, 'learning_rate': 9.943858660656795e-05, 'epoch': 0.22}\n",
            "{'loss': 3.4796, 'learning_rate': 9.942852543464262e-05, 'epoch': 0.22}\n",
            "{'loss': 5.8129, 'learning_rate': 9.941846426271733e-05, 'epoch': 0.22}\n",
            "{'loss': 6.7383, 'learning_rate': 9.940840309079202e-05, 'epoch': 0.22}\n",
            "{'loss': 6.1051, 'learning_rate': 9.939834191886671e-05, 'epoch': 0.22}\n",
            "{'loss': 5.6231, 'learning_rate': 9.93882807469414e-05, 'epoch': 0.22}\n",
            "{'loss': 4.9245, 'learning_rate': 9.937821957501611e-05, 'epoch': 0.22}\n",
            "{'loss': 4.9764, 'learning_rate': 9.936815840309079e-05, 'epoch': 0.22}\n",
            "{'loss': 4.5248, 'learning_rate': 9.93580972311655e-05, 'epoch': 0.22}\n",
            "{'loss': 4.2471, 'learning_rate': 9.934803605924019e-05, 'epoch': 0.22}\n",
            "{'loss': 4.1764, 'learning_rate': 9.933797488731488e-05, 'epoch': 0.23}\n",
            "{'loss': 3.3443, 'learning_rate': 9.932791371538957e-05, 'epoch': 0.23}\n",
            "{'loss': 6.5389, 'learning_rate': 9.931785254346426e-05, 'epoch': 0.23}\n",
            "{'loss': 7.416, 'learning_rate': 9.930779137153895e-05, 'epoch': 0.23}\n",
            "{'loss': 5.3235, 'learning_rate': 9.929773019961366e-05, 'epoch': 0.23}\n",
            "{'loss': 6.7869, 'learning_rate': 9.928766902768835e-05, 'epoch': 0.23}\n",
            "{'loss': 7.0138, 'learning_rate': 9.927760785576304e-05, 'epoch': 0.23}\n",
            "{'loss': 5.5241, 'learning_rate': 9.926754668383774e-05, 'epoch': 0.23}\n",
            "{'loss': 4.7311, 'learning_rate': 9.925748551191243e-05, 'epoch': 0.23}\n",
            "{'loss': 4.9264, 'learning_rate': 9.924742433998713e-05, 'epoch': 0.23}\n",
            "{'loss': 3.9453, 'learning_rate': 9.923736316806182e-05, 'epoch': 0.23}\n",
            "{'loss': 4.728, 'learning_rate': 9.922730199613652e-05, 'epoch': 0.23}\n",
            "{'loss': 5.5253, 'learning_rate': 9.921724082421121e-05, 'epoch': 0.23}\n",
            "{'loss': 5.5327, 'learning_rate': 9.92071796522859e-05, 'epoch': 0.23}\n",
            "{'loss': 5.9169, 'learning_rate': 9.919711848036059e-05, 'epoch': 0.23}\n",
            "{'loss': 5.2345, 'learning_rate': 9.91870573084353e-05, 'epoch': 0.23}\n",
            "{'loss': 5.4897, 'learning_rate': 9.917699613650998e-05, 'epoch': 0.23}\n",
            "{'loss': 4.7891, 'learning_rate': 9.916693496458468e-05, 'epoch': 0.23}\n",
            "{'loss': 4.6938, 'learning_rate': 9.915687379265937e-05, 'epoch': 0.23}\n",
            "{'loss': 4.7547, 'learning_rate': 9.914681262073407e-05, 'epoch': 0.23}\n",
            "{'loss': 3.8362, 'learning_rate': 9.913675144880876e-05, 'epoch': 0.23}\n",
            "{'loss': 3.5097, 'learning_rate': 9.912669027688346e-05, 'epoch': 0.23}\n",
            "{'loss': 6.3283, 'learning_rate': 9.911662910495814e-05, 'epoch': 0.23}\n",
            "{'loss': 5.8146, 'learning_rate': 9.910656793303285e-05, 'epoch': 0.23}\n",
            "{'loss': 5.8122, 'learning_rate': 9.909650676110754e-05, 'epoch': 0.23}\n",
            "{'loss': 5.621, 'learning_rate': 9.908644558918223e-05, 'epoch': 0.23}\n",
            "{'loss': 4.7565, 'learning_rate': 9.907638441725692e-05, 'epoch': 0.24}\n",
            "{'loss': 4.3509, 'learning_rate': 9.906632324533161e-05, 'epoch': 0.24}\n",
            "{'loss': 5.1975, 'learning_rate': 9.905626207340632e-05, 'epoch': 0.24}\n",
            "{'loss': 4.3704, 'learning_rate': 9.904620090148101e-05, 'epoch': 0.24}\n",
            "{'loss': 5.1693, 'learning_rate': 9.90361397295557e-05, 'epoch': 0.24}\n",
            "{'loss': 3.2271, 'learning_rate': 9.90260785576304e-05, 'epoch': 0.24}\n",
            "{'loss': 6.9259, 'learning_rate': 9.90160173857051e-05, 'epoch': 0.24}\n",
            "{'loss': 7.6887, 'learning_rate': 9.900595621377978e-05, 'epoch': 0.24}\n",
            "{'loss': 5.632, 'learning_rate': 9.899589504185448e-05, 'epoch': 0.24}\n",
            "{'loss': 5.4421, 'learning_rate': 9.898583386992918e-05, 'epoch': 0.24}\n",
            "{'loss': 4.7406, 'learning_rate': 9.897577269800387e-05, 'epoch': 0.24}\n",
            "{'loss': 5.5932, 'learning_rate': 9.896571152607856e-05, 'epoch': 0.24}\n",
            "{'loss': 4.986, 'learning_rate': 9.895565035415327e-05, 'epoch': 0.24}\n",
            "{'loss': 4.2391, 'learning_rate': 9.894558918222794e-05, 'epoch': 0.24}\n",
            "{'loss': 4.4405, 'learning_rate': 9.893552801030265e-05, 'epoch': 0.24}\n",
            "{'loss': 3.739, 'learning_rate': 9.892546683837733e-05, 'epoch': 0.24}\n",
            "{'loss': 6.0772, 'learning_rate': 9.891540566645203e-05, 'epoch': 0.24}\n",
            "{'loss': 5.984, 'learning_rate': 9.890534449452673e-05, 'epoch': 0.24}\n",
            "{'loss': 6.3562, 'learning_rate': 9.889528332260142e-05, 'epoch': 0.24}\n",
            "{'loss': 5.8816, 'learning_rate': 9.888522215067611e-05, 'epoch': 0.24}\n",
            "{'loss': 5.2789, 'learning_rate': 9.887516097875081e-05, 'epoch': 0.24}\n",
            "{'loss': 5.4261, 'learning_rate': 9.88650998068255e-05, 'epoch': 0.24}\n",
            "{'loss': 5.4995, 'learning_rate': 9.88550386349002e-05, 'epoch': 0.24}\n",
            "{'loss': 4.6616, 'learning_rate': 9.884497746297489e-05, 'epoch': 0.24}\n",
            "{'loss': 4.276, 'learning_rate': 9.883491629104958e-05, 'epoch': 0.24}\n",
            "{'loss': 3.9725, 'learning_rate': 9.882485511912429e-05, 'epoch': 0.24}\n",
            "{'loss': 5.8479, 'learning_rate': 9.881479394719897e-05, 'epoch': 0.25}\n",
            "{'loss': 5.4412, 'learning_rate': 9.880473277527367e-05, 'epoch': 0.25}\n",
            "{'loss': 5.3647, 'learning_rate': 9.879467160334836e-05, 'epoch': 0.25}\n",
            "{'loss': 5.2285, 'learning_rate': 9.878461043142306e-05, 'epoch': 0.25}\n",
            "{'loss': 4.8772, 'learning_rate': 9.877454925949775e-05, 'epoch': 0.25}\n",
            "{'loss': 4.8819, 'learning_rate': 9.876448808757245e-05, 'epoch': 0.25}\n",
            "{'loss': 4.7343, 'learning_rate': 9.875442691564713e-05, 'epoch': 0.25}\n",
            "{'loss': 4.3084, 'learning_rate': 9.874436574372184e-05, 'epoch': 0.25}\n",
            "{'loss': 4.169, 'learning_rate': 9.873430457179653e-05, 'epoch': 0.25}\n",
            "{'loss': 3.4156, 'learning_rate': 9.872424339987122e-05, 'epoch': 0.25}\n",
            "{'loss': 6.0132, 'learning_rate': 9.871418222794591e-05, 'epoch': 0.25}\n",
            "{'loss': 5.6664, 'learning_rate': 9.870412105602062e-05, 'epoch': 0.25}\n",
            "{'loss': 5.6165, 'learning_rate': 9.86940598840953e-05, 'epoch': 0.25}\n",
            "{'loss': 5.49, 'learning_rate': 9.868399871217e-05, 'epoch': 0.25}\n",
            "{'loss': 4.8351, 'learning_rate': 9.86739375402447e-05, 'epoch': 0.25}\n",
            "{'loss': 4.6728, 'learning_rate': 9.866387636831939e-05, 'epoch': 0.25}\n",
            "{'loss': 4.3426, 'learning_rate': 9.865381519639408e-05, 'epoch': 0.25}\n",
            "{'loss': 4.358, 'learning_rate': 9.864375402446877e-05, 'epoch': 0.25}\n",
            "{'loss': 4.2455, 'learning_rate': 9.863369285254347e-05, 'epoch': 0.25}\n",
            "{'loss': 3.1423, 'learning_rate': 9.862363168061817e-05, 'epoch': 0.25}\n",
            "{'loss': 5.8557, 'learning_rate': 9.861357050869286e-05, 'epoch': 0.25}\n",
            "{'loss': 6.3306, 'learning_rate': 9.860350933676755e-05, 'epoch': 0.25}\n",
            "{'loss': 5.5236, 'learning_rate': 9.859344816484226e-05, 'epoch': 0.25}\n",
            "{'loss': 5.2366, 'learning_rate': 9.858338699291693e-05, 'epoch': 0.25}\n",
            "{'loss': 5.004, 'learning_rate': 9.857332582099164e-05, 'epoch': 0.25}\n",
            "{'loss': 4.6839, 'learning_rate': 9.856326464906632e-05, 'epoch': 0.25}\n",
            "{'loss': 4.6018, 'learning_rate': 9.855320347714102e-05, 'epoch': 0.26}\n",
            "{'loss': 4.3824, 'learning_rate': 9.854314230521572e-05, 'epoch': 0.26}\n",
            "{'loss': 4.0188, 'learning_rate': 9.853308113329041e-05, 'epoch': 0.26}\n",
            "{'loss': 3.8854, 'learning_rate': 9.85230199613651e-05, 'epoch': 0.26}\n",
            "{'loss': 6.3109, 'learning_rate': 9.85129587894398e-05, 'epoch': 0.26}\n",
            "{'loss': 5.6361, 'learning_rate': 9.850289761751448e-05, 'epoch': 0.26}\n",
            "{'loss': 5.6067, 'learning_rate': 9.849283644558919e-05, 'epoch': 0.26}\n",
            "{'loss': 5.9275, 'learning_rate': 9.848277527366388e-05, 'epoch': 0.26}\n",
            "{'loss': 5.1695, 'learning_rate': 9.847271410173857e-05, 'epoch': 0.26}\n",
            "{'loss': 5.8752, 'learning_rate': 9.846265292981326e-05, 'epoch': 0.26}\n",
            "{'loss': 4.42, 'learning_rate': 9.845259175788797e-05, 'epoch': 0.26}\n",
            "{'loss': 4.2573, 'learning_rate': 9.844253058596266e-05, 'epoch': 0.26}\n",
            "{'loss': 4.543, 'learning_rate': 9.843246941403735e-05, 'epoch': 0.26}\n",
            "{'loss': 3.3094, 'learning_rate': 9.842240824211205e-05, 'epoch': 0.26}\n",
            "{'loss': 5.783, 'learning_rate': 9.841234707018674e-05, 'epoch': 0.26}\n",
            "{'loss': 5.9624, 'learning_rate': 9.840228589826144e-05, 'epoch': 0.26}\n",
            "{'loss': 5.5884, 'learning_rate': 9.839222472633612e-05, 'epoch': 0.26}\n",
            "{'loss': 5.2483, 'learning_rate': 9.838216355441083e-05, 'epoch': 0.26}\n",
            "{'loss': 5.2859, 'learning_rate': 9.837210238248552e-05, 'epoch': 0.26}\n",
            "{'loss': 4.8401, 'learning_rate': 9.836204121056021e-05, 'epoch': 0.26}\n",
            "{'loss': 5.0675, 'learning_rate': 9.83519800386349e-05, 'epoch': 0.26}\n",
            "{'loss': 4.5761, 'learning_rate': 9.834191886670961e-05, 'epoch': 0.26}\n",
            "{'loss': 4.4772, 'learning_rate': 9.833185769478429e-05, 'epoch': 0.26}\n",
            "{'loss': 4.149, 'learning_rate': 9.832179652285899e-05, 'epoch': 0.26}\n",
            "{'loss': 5.7425, 'learning_rate': 9.831173535093368e-05, 'epoch': 0.26}\n",
            "{'loss': 6.0606, 'learning_rate': 9.830167417900838e-05, 'epoch': 0.26}\n",
            "{'loss': 6.4678, 'learning_rate': 9.829161300708307e-05, 'epoch': 0.26}\n",
            "{'loss': 5.251, 'learning_rate': 9.828155183515776e-05, 'epoch': 0.27}\n",
            "{'loss': 5.8134, 'learning_rate': 9.827149066323245e-05, 'epoch': 0.27}\n",
            "{'loss': 4.7358, 'learning_rate': 9.826142949130716e-05, 'epoch': 0.27}\n",
            "{'loss': 4.6996, 'learning_rate': 9.825136831938185e-05, 'epoch': 0.27}\n",
            "{'loss': 4.8165, 'learning_rate': 9.824130714745654e-05, 'epoch': 0.27}\n",
            "{'loss': 4.3484, 'learning_rate': 9.823124597553123e-05, 'epoch': 0.27}\n",
            "{'loss': 3.363, 'learning_rate': 9.822118480360592e-05, 'epoch': 0.27}\n",
            "{'loss': 5.8004, 'learning_rate': 9.821112363168063e-05, 'epoch': 0.27}\n",
            "{'loss': 5.62, 'learning_rate': 9.820106245975532e-05, 'epoch': 0.27}\n",
            "{'loss': 5.0366, 'learning_rate': 9.819100128783001e-05, 'epoch': 0.27}\n",
            "{'loss': 5.212, 'learning_rate': 9.81809401159047e-05, 'epoch': 0.27}\n",
            "{'loss': 4.6355, 'learning_rate': 9.81708789439794e-05, 'epoch': 0.27}\n",
            "{'loss': 5.0416, 'learning_rate': 9.816081777205409e-05, 'epoch': 0.27}\n",
            "{'loss': 4.5396, 'learning_rate': 9.81507566001288e-05, 'epoch': 0.27}\n",
            "{'loss': 4.1916, 'learning_rate': 9.814069542820347e-05, 'epoch': 0.27}\n",
            "{'loss': 4.2042, 'learning_rate': 9.813063425627818e-05, 'epoch': 0.27}\n",
            "{'loss': 3.1393, 'learning_rate': 9.812057308435287e-05, 'epoch': 0.27}\n",
            "{'loss': 6.5274, 'learning_rate': 9.811051191242756e-05, 'epoch': 0.27}\n",
            "{'loss': 5.7041, 'learning_rate': 9.810045074050225e-05, 'epoch': 0.27}\n",
            "{'loss': 5.957, 'learning_rate': 9.809038956857696e-05, 'epoch': 0.27}\n",
            "{'loss': 5.6416, 'learning_rate': 9.808032839665164e-05, 'epoch': 0.27}\n",
            "{'loss': 5.0957, 'learning_rate': 9.807026722472634e-05, 'epoch': 0.27}\n",
            "{'loss': 5.1423, 'learning_rate': 9.806020605280104e-05, 'epoch': 0.27}\n",
            "{'loss': 4.6355, 'learning_rate': 9.805014488087573e-05, 'epoch': 0.27}\n",
            "{'loss': 4.4021, 'learning_rate': 9.804008370895042e-05, 'epoch': 0.27}\n",
            "{'loss': 3.8479, 'learning_rate': 9.803002253702511e-05, 'epoch': 0.27}\n",
            "{'loss': 3.7514, 'learning_rate': 9.801996136509982e-05, 'epoch': 0.28}\n",
            "{'loss': 6.7179, 'learning_rate': 9.800990019317451e-05, 'epoch': 0.28}\n",
            "{'loss': 6.1891, 'learning_rate': 9.79998390212492e-05, 'epoch': 0.28}\n",
            "{'loss': 5.5547, 'learning_rate': 9.798977784932389e-05, 'epoch': 0.28}\n",
            "{'loss': 5.2156, 'learning_rate': 9.79797166773986e-05, 'epoch': 0.28}\n",
            "{'loss': 5.0421, 'learning_rate': 9.796965550547328e-05, 'epoch': 0.28}\n",
            "{'loss': 5.009, 'learning_rate': 9.795959433354798e-05, 'epoch': 0.28}\n",
            "{'loss': 4.7369, 'learning_rate': 9.794953316162267e-05, 'epoch': 0.28}\n",
            "{'loss': 4.2875, 'learning_rate': 9.793947198969737e-05, 'epoch': 0.28}\n",
            "{'loss': 5.3794, 'learning_rate': 9.792941081777206e-05, 'epoch': 0.28}\n",
            "{'loss': 3.4502, 'learning_rate': 9.791934964584675e-05, 'epoch': 0.28}\n",
            "{'loss': 6.0839, 'learning_rate': 9.790928847392144e-05, 'epoch': 0.28}\n",
            "{'loss': 6.6576, 'learning_rate': 9.789922730199615e-05, 'epoch': 0.28}\n",
            "{'loss': 5.6619, 'learning_rate': 9.788916613007082e-05, 'epoch': 0.28}\n",
            "{'loss': 5.5135, 'learning_rate': 9.787910495814553e-05, 'epoch': 0.28}\n",
            "{'loss': 5.6965, 'learning_rate': 9.786904378622022e-05, 'epoch': 0.28}\n",
            "{'loss': 5.5793, 'learning_rate': 9.785898261429491e-05, 'epoch': 0.28}\n",
            "{'loss': 4.8297, 'learning_rate': 9.78489214423696e-05, 'epoch': 0.28}\n",
            "{'loss': 4.8398, 'learning_rate': 9.783886027044431e-05, 'epoch': 0.28}\n",
            "{'loss': 4.4087, 'learning_rate': 9.7828799098519e-05, 'epoch': 0.28}\n",
            "{'loss': 3.7716, 'learning_rate': 9.78187379265937e-05, 'epoch': 0.28}\n",
            "{'loss': 5.7037, 'learning_rate': 9.780867675466839e-05, 'epoch': 0.28}\n",
            "{'loss': 5.3826, 'learning_rate': 9.779861558274308e-05, 'epoch': 0.28}\n",
            "{'loss': 5.4177, 'learning_rate': 9.778855441081778e-05, 'epoch': 0.28}\n",
            "{'loss': 5.2499, 'learning_rate': 9.777849323889246e-05, 'epoch': 0.28}\n",
            "{'loss': 5.0206, 'learning_rate': 9.776843206696717e-05, 'epoch': 0.28}\n",
            "{'loss': 5.0213, 'learning_rate': 9.775837089504186e-05, 'epoch': 0.29}\n",
            "{'loss': 4.3785, 'learning_rate': 9.774830972311655e-05, 'epoch': 0.29}\n",
            "{'loss': 4.6704, 'learning_rate': 9.773824855119124e-05, 'epoch': 0.29}\n",
            "{'loss': 4.9404, 'learning_rate': 9.772818737926595e-05, 'epoch': 0.29}\n",
            "{'loss': 4.2158, 'learning_rate': 9.771812620734063e-05, 'epoch': 0.29}\n",
            "{'loss': 6.1198, 'learning_rate': 9.770806503541533e-05, 'epoch': 0.29}\n",
            "{'loss': 5.7373, 'learning_rate': 9.769800386349003e-05, 'epoch': 0.29}\n",
            "{'loss': 5.3546, 'learning_rate': 9.768794269156472e-05, 'epoch': 0.29}\n",
            "{'loss': 6.768, 'learning_rate': 9.767788151963941e-05, 'epoch': 0.29}\n",
            "{'loss': 5.8214, 'learning_rate': 9.766782034771411e-05, 'epoch': 0.29}\n",
            "{'loss': 4.9545, 'learning_rate': 9.765775917578879e-05, 'epoch': 0.29}\n",
            "{'loss': 5.1192, 'learning_rate': 9.76476980038635e-05, 'epoch': 0.29}\n",
            "{'loss': 4.4707, 'learning_rate': 9.763763683193819e-05, 'epoch': 0.29}\n",
            "{'loss': 4.5884, 'learning_rate': 9.762757566001288e-05, 'epoch': 0.29}\n",
            "{'loss': 3.8476, 'learning_rate': 9.761751448808757e-05, 'epoch': 0.29}\n",
            "{'loss': 5.9966, 'learning_rate': 9.760745331616227e-05, 'epoch': 0.29}\n",
            "{'loss': 5.4586, 'learning_rate': 9.759739214423697e-05, 'epoch': 0.29}\n",
            "{'loss': 5.878, 'learning_rate': 9.758733097231166e-05, 'epoch': 0.29}\n",
            "{'loss': 5.6943, 'learning_rate': 9.757726980038636e-05, 'epoch': 0.29}\n",
            "{'loss': 5.3185, 'learning_rate': 9.756720862846105e-05, 'epoch': 0.29}\n",
            "{'loss': 5.0569, 'learning_rate': 9.755714745653575e-05, 'epoch': 0.29}\n",
            "{'loss': 5.2661, 'learning_rate': 9.754708628461043e-05, 'epoch': 0.29}\n",
            "{'loss': 4.5535, 'learning_rate': 9.753702511268514e-05, 'epoch': 0.29}\n",
            "{'loss': 4.4702, 'learning_rate': 9.752696394075981e-05, 'epoch': 0.29}\n",
            "{'loss': 3.7322, 'learning_rate': 9.751690276883452e-05, 'epoch': 0.29}\n",
            "{'loss': 6.2653, 'learning_rate': 9.750684159690921e-05, 'epoch': 0.29}\n",
            "{'loss': 6.0871, 'learning_rate': 9.74967804249839e-05, 'epoch': 0.3}\n",
            "{'loss': 5.4597, 'learning_rate': 9.74867192530586e-05, 'epoch': 0.3}\n",
            "{'loss': 6.0964, 'learning_rate': 9.74766580811333e-05, 'epoch': 0.3}\n",
            "{'loss': 5.2178, 'learning_rate': 9.746659690920798e-05, 'epoch': 0.3}\n",
            "{'loss': 4.8606, 'learning_rate': 9.745653573728269e-05, 'epoch': 0.3}\n",
            "{'loss': 5.1736, 'learning_rate': 9.744647456535738e-05, 'epoch': 0.3}\n",
            "{'loss': 4.5459, 'learning_rate': 9.743641339343207e-05, 'epoch': 0.3}\n",
            "{'loss': 4.197, 'learning_rate': 9.742635222150676e-05, 'epoch': 0.3}\n",
            "{'loss': 3.3014, 'learning_rate': 9.741629104958147e-05, 'epoch': 0.3}\n",
            "{'loss': 6.0015, 'learning_rate': 9.740622987765616e-05, 'epoch': 0.3}\n",
            "{'loss': 5.9829, 'learning_rate': 9.739616870573085e-05, 'epoch': 0.3}\n",
            "{'loss': 5.8537, 'learning_rate': 9.738610753380554e-05, 'epoch': 0.3}\n",
            "{'loss': 5.0447, 'learning_rate': 9.737604636188023e-05, 'epoch': 0.3}\n",
            "{'loss': 5.2179, 'learning_rate': 9.736598518995494e-05, 'epoch': 0.3}\n",
            "{'loss': 5.1312, 'learning_rate': 9.735592401802962e-05, 'epoch': 0.3}\n",
            "{'loss': 4.7062, 'learning_rate': 9.734586284610432e-05, 'epoch': 0.3}\n",
            "{'loss': 4.0877, 'learning_rate': 9.733580167417902e-05, 'epoch': 0.3}\n",
            "{'loss': 4.4606, 'learning_rate': 9.732574050225371e-05, 'epoch': 0.3}\n",
            "{'loss': 4.0083, 'learning_rate': 9.73156793303284e-05, 'epoch': 0.3}\n",
            "{'loss': 5.7136, 'learning_rate': 9.73056181584031e-05, 'epoch': 0.3}\n",
            "{'loss': 5.8406, 'learning_rate': 9.729555698647778e-05, 'epoch': 0.3}\n",
            "{'loss': 5.9, 'learning_rate': 9.728549581455249e-05, 'epoch': 0.3}\n",
            "{'loss': 5.1569, 'learning_rate': 9.727543464262718e-05, 'epoch': 0.3}\n",
            "{'loss': 4.9551, 'learning_rate': 9.726537347070187e-05, 'epoch': 0.3}\n",
            "{'loss': 4.5025, 'learning_rate': 9.725531229877656e-05, 'epoch': 0.3}\n",
            "{'loss': 4.4027, 'learning_rate': 9.724525112685126e-05, 'epoch': 0.3}\n",
            "{'loss': 4.1274, 'learning_rate': 9.723518995492595e-05, 'epoch': 0.31}\n",
            "{'loss': 4.3686, 'learning_rate': 9.722512878300065e-05, 'epoch': 0.31}\n",
            "{'loss': 3.9433, 'learning_rate': 9.721506761107535e-05, 'epoch': 0.31}\n",
            "{'loss': 5.8912, 'learning_rate': 9.720500643915004e-05, 'epoch': 0.31}\n",
            "{'loss': 5.8819, 'learning_rate': 9.719494526722473e-05, 'epoch': 0.31}\n",
            "{'loss': 5.8256, 'learning_rate': 9.718488409529942e-05, 'epoch': 0.31}\n",
            "{'loss': 5.7487, 'learning_rate': 9.717482292337413e-05, 'epoch': 0.31}\n",
            "{'loss': 6.1903, 'learning_rate': 9.716476175144882e-05, 'epoch': 0.31}\n",
            "{'loss': 6.064, 'learning_rate': 9.715470057952351e-05, 'epoch': 0.31}\n",
            "{'loss': 5.4367, 'learning_rate': 9.71446394075982e-05, 'epoch': 0.31}\n",
            "{'loss': 4.3282, 'learning_rate': 9.71345782356729e-05, 'epoch': 0.31}\n",
            "{'loss': 4.0038, 'learning_rate': 9.712451706374759e-05, 'epoch': 0.31}\n",
            "{'loss': 3.5468, 'learning_rate': 9.711445589182229e-05, 'epoch': 0.31}\n",
            "{'loss': 5.8495, 'learning_rate': 9.710439471989697e-05, 'epoch': 0.31}\n",
            "{'loss': 5.5361, 'learning_rate': 9.709433354797168e-05, 'epoch': 0.31}\n",
            "{'loss': 6.0291, 'learning_rate': 9.708427237604637e-05, 'epoch': 0.31}\n",
            "{'loss': 5.1446, 'learning_rate': 9.707421120412106e-05, 'epoch': 0.31}\n",
            "{'loss': 5.3264, 'learning_rate': 9.706415003219575e-05, 'epoch': 0.31}\n",
            "{'loss': 4.8875, 'learning_rate': 9.705408886027046e-05, 'epoch': 0.31}\n",
            "{'loss': 4.69, 'learning_rate': 9.704402768834513e-05, 'epoch': 0.31}\n",
            "{'loss': 4.7514, 'learning_rate': 9.703396651641984e-05, 'epoch': 0.31}\n",
            "{'loss': 3.8844, 'learning_rate': 9.702390534449453e-05, 'epoch': 0.31}\n",
            "{'loss': 3.0858, 'learning_rate': 9.701384417256922e-05, 'epoch': 0.31}\n",
            "{'loss': 5.5703, 'learning_rate': 9.700378300064392e-05, 'epoch': 0.31}\n",
            "{'loss': 5.6124, 'learning_rate': 9.699372182871861e-05, 'epoch': 0.31}\n",
            "{'loss': 5.6943, 'learning_rate': 9.698366065679331e-05, 'epoch': 0.31}\n",
            "{'loss': 5.8572, 'learning_rate': 9.6973599484868e-05, 'epoch': 0.32}\n",
            "{'loss': 5.8022, 'learning_rate': 9.69635383129427e-05, 'epoch': 0.32}\n",
            "{'loss': 4.7206, 'learning_rate': 9.695347714101739e-05, 'epoch': 0.32}\n",
            "{'loss': 4.6327, 'learning_rate': 9.69434159690921e-05, 'epoch': 0.32}\n",
            "{'loss': 4.7918, 'learning_rate': 9.693335479716677e-05, 'epoch': 0.32}\n",
            "{'loss': 3.6648, 'learning_rate': 9.692329362524148e-05, 'epoch': 0.32}\n",
            "{'loss': 3.248, 'learning_rate': 9.691323245331617e-05, 'epoch': 0.32}\n",
            "{'loss': 5.707, 'learning_rate': 9.690317128139086e-05, 'epoch': 0.32}\n",
            "{'loss': 5.896, 'learning_rate': 9.689311010946555e-05, 'epoch': 0.32}\n",
            "{'loss': 5.4121, 'learning_rate': 9.688304893754025e-05, 'epoch': 0.32}\n",
            "{'loss': 5.3437, 'learning_rate': 9.687298776561494e-05, 'epoch': 0.32}\n",
            "{'loss': 5.6211, 'learning_rate': 9.686292659368964e-05, 'epoch': 0.32}\n",
            "{'loss': 4.892, 'learning_rate': 9.685286542176432e-05, 'epoch': 0.32}\n",
            "{'loss': 4.5024, 'learning_rate': 9.684280424983903e-05, 'epoch': 0.32}\n",
            "{'loss': 5.2177, 'learning_rate': 9.683274307791372e-05, 'epoch': 0.32}\n",
            "{'loss': 4.2567, 'learning_rate': 9.682268190598841e-05, 'epoch': 0.32}\n",
            "{'loss': 2.9463, 'learning_rate': 9.68126207340631e-05, 'epoch': 0.32}\n",
            "{'loss': 6.3414, 'learning_rate': 9.680255956213781e-05, 'epoch': 0.32}\n",
            "{'loss': 5.9584, 'learning_rate': 9.67924983902125e-05, 'epoch': 0.32}\n",
            "{'loss': 5.8259, 'learning_rate': 9.678243721828719e-05, 'epoch': 0.32}\n",
            "{'loss': 5.4773, 'learning_rate': 9.677237604636188e-05, 'epoch': 0.32}\n",
            "{'loss': 5.4919, 'learning_rate': 9.676231487443658e-05, 'epoch': 0.32}\n",
            "{'loss': 5.5386, 'learning_rate': 9.675225370251128e-05, 'epoch': 0.32}\n",
            "{'loss': 5.1665, 'learning_rate': 9.674219253058596e-05, 'epoch': 0.32}\n",
            "{'loss': 4.9399, 'learning_rate': 9.673213135866067e-05, 'epoch': 0.32}\n",
            "{'loss': 3.8466, 'learning_rate': 9.672207018673536e-05, 'epoch': 0.32}\n",
            "{'loss': 3.4696, 'learning_rate': 9.671200901481005e-05, 'epoch': 0.32}\n",
            "{'loss': 5.9239, 'learning_rate': 9.670194784288474e-05, 'epoch': 0.33}\n",
            "{'loss': 5.4351, 'learning_rate': 9.669188667095945e-05, 'epoch': 0.33}\n",
            "{'loss': 4.9452, 'learning_rate': 9.668182549903412e-05, 'epoch': 0.33}\n",
            "{'loss': 5.0086, 'learning_rate': 9.667176432710883e-05, 'epoch': 0.33}\n",
            "{'loss': 4.9696, 'learning_rate': 9.666170315518352e-05, 'epoch': 0.33}\n",
            "{'loss': 4.7103, 'learning_rate': 9.665164198325821e-05, 'epoch': 0.33}\n",
            "{'loss': 4.8574, 'learning_rate': 9.66415808113329e-05, 'epoch': 0.33}\n",
            "{'loss': 4.414, 'learning_rate': 9.663151963940761e-05, 'epoch': 0.33}\n",
            "{'loss': 4.2146, 'learning_rate': 9.662145846748229e-05, 'epoch': 0.33}\n",
            "{'loss': 4.9795, 'learning_rate': 9.6611397295557e-05, 'epoch': 0.33}\n",
            "{'loss': 5.9929, 'learning_rate': 9.660133612363169e-05, 'epoch': 0.33}\n",
            "{'loss': 6.3588, 'learning_rate': 9.659127495170638e-05, 'epoch': 0.33}\n",
            "{'loss': 5.3599, 'learning_rate': 9.658121377978107e-05, 'epoch': 0.33}\n",
            "{'loss': 5.9049, 'learning_rate': 9.657115260785576e-05, 'epoch': 0.33}\n",
            "{'loss': 4.6967, 'learning_rate': 9.656109143593047e-05, 'epoch': 0.33}\n",
            "{'loss': 4.9294, 'learning_rate': 9.655103026400516e-05, 'epoch': 0.33}\n",
            "{'loss': 4.7367, 'learning_rate': 9.654096909207985e-05, 'epoch': 0.33}\n",
            "{'loss': 4.3335, 'learning_rate': 9.653090792015454e-05, 'epoch': 0.33}\n",
            "{'loss': 3.7995, 'learning_rate': 9.652084674822925e-05, 'epoch': 0.33}\n",
            "{'loss': 3.2922, 'learning_rate': 9.651078557630393e-05, 'epoch': 0.33}\n",
            "{'loss': 6.0291, 'learning_rate': 9.650072440437863e-05, 'epoch': 0.33}\n",
            "{'loss': 5.4325, 'learning_rate': 9.649066323245331e-05, 'epoch': 0.33}\n",
            "{'loss': 5.8158, 'learning_rate': 9.648060206052802e-05, 'epoch': 0.33}\n",
            "{'loss': 5.6836, 'learning_rate': 9.647054088860271e-05, 'epoch': 0.33}\n",
            "{'loss': 5.2546, 'learning_rate': 9.64604797166774e-05, 'epoch': 0.33}\n",
            "{'loss': 5.1457, 'learning_rate': 9.645041854475209e-05, 'epoch': 0.33}\n",
            "{'loss': 5.0471, 'learning_rate': 9.64403573728268e-05, 'epoch': 0.34}\n",
            "{'loss': 4.6288, 'learning_rate': 9.643029620090148e-05, 'epoch': 0.34}\n",
            "{'loss': 4.2987, 'learning_rate': 9.642023502897618e-05, 'epoch': 0.34}\n",
            "{'loss': 4.0445, 'learning_rate': 9.641017385705087e-05, 'epoch': 0.34}\n",
            "{'loss': 5.7523, 'learning_rate': 9.640011268512557e-05, 'epoch': 0.34}\n",
            "{'loss': 5.7115, 'learning_rate': 9.639005151320026e-05, 'epoch': 0.34}\n",
            "{'loss': 5.9153, 'learning_rate': 9.637999034127496e-05, 'epoch': 0.34}\n",
            "{'loss': 5.9325, 'learning_rate': 9.636992916934965e-05, 'epoch': 0.34}\n",
            "{'loss': 4.5591, 'learning_rate': 9.635986799742435e-05, 'epoch': 0.34}\n",
            "{'loss': 4.742, 'learning_rate': 9.634980682549904e-05, 'epoch': 0.34}\n",
            "{'loss': 4.454, 'learning_rate': 9.633974565357373e-05, 'epoch': 0.34}\n",
            "{'loss': 4.4181, 'learning_rate': 9.632968448164844e-05, 'epoch': 0.34}\n",
            "{'loss': 4.1367, 'learning_rate': 9.631962330972311e-05, 'epoch': 0.34}\n",
            "{'loss': 4.1044, 'learning_rate': 9.630956213779782e-05, 'epoch': 0.34}\n",
            "{'loss': 6.1966, 'learning_rate': 9.629950096587251e-05, 'epoch': 0.34}\n",
            "{'loss': 6.1644, 'learning_rate': 9.62894397939472e-05, 'epoch': 0.34}\n",
            "{'loss': 5.7238, 'learning_rate': 9.62793786220219e-05, 'epoch': 0.34}\n",
            "{'loss': 4.9074, 'learning_rate': 9.62693174500966e-05, 'epoch': 0.34}\n",
            "{'loss': 5.5184, 'learning_rate': 9.625925627817128e-05, 'epoch': 0.34}\n",
            "{'loss': 5.0943, 'learning_rate': 9.624919510624598e-05, 'epoch': 0.34}\n",
            "{'loss': 4.5649, 'learning_rate': 9.623913393432066e-05, 'epoch': 0.34}\n",
            "{'loss': 4.9804, 'learning_rate': 9.622907276239537e-05, 'epoch': 0.34}\n",
            "{'loss': 4.0329, 'learning_rate': 9.621901159047006e-05, 'epoch': 0.34}\n",
            "{'loss': 3.9396, 'learning_rate': 9.620895041854475e-05, 'epoch': 0.34}\n",
            "{'loss': 6.0912, 'learning_rate': 9.619888924661944e-05, 'epoch': 0.34}\n",
            "{'loss': 5.865, 'learning_rate': 9.618882807469415e-05, 'epoch': 0.34}\n",
            "{'loss': 5.2403, 'learning_rate': 9.617876690276884e-05, 'epoch': 0.35}\n",
            "{'loss': 5.2024, 'learning_rate': 9.616870573084353e-05, 'epoch': 0.35}\n",
            "{'loss': 5.1057, 'learning_rate': 9.615864455891823e-05, 'epoch': 0.35}\n",
            "{'loss': 5.2301, 'learning_rate': 9.614858338699292e-05, 'epoch': 0.35}\n",
            "{'loss': 4.4801, 'learning_rate': 9.613852221506762e-05, 'epoch': 0.35}\n",
            "{'loss': 4.4399, 'learning_rate': 9.612846104314231e-05, 'epoch': 0.35}\n",
            "{'loss': 3.9274, 'learning_rate': 9.611839987121701e-05, 'epoch': 0.35}\n",
            "{'loss': 3.3201, 'learning_rate': 9.61083386992917e-05, 'epoch': 0.35}\n",
            "{'loss': 6.3713, 'learning_rate': 9.609827752736639e-05, 'epoch': 0.35}\n",
            "{'loss': 5.4704, 'learning_rate': 9.608821635544108e-05, 'epoch': 0.35}\n",
            "{'loss': 5.7236, 'learning_rate': 9.607815518351579e-05, 'epoch': 0.35}\n",
            "{'loss': 5.1901, 'learning_rate': 9.606809401159047e-05, 'epoch': 0.35}\n",
            "{'loss': 4.817, 'learning_rate': 9.605803283966517e-05, 'epoch': 0.35}\n",
            "{'loss': 4.9163, 'learning_rate': 9.604797166773986e-05, 'epoch': 0.35}\n",
            "{'loss': 4.5491, 'learning_rate': 9.603791049581456e-05, 'epoch': 0.35}\n",
            "{'loss': 4.2514, 'learning_rate': 9.602784932388925e-05, 'epoch': 0.35}\n",
            "{'loss': 4.1471, 'learning_rate': 9.601778815196395e-05, 'epoch': 0.35}\n",
            "{'loss': 3.7412, 'learning_rate': 9.600772698003863e-05, 'epoch': 0.35}\n",
            "{'loss': 5.9189, 'learning_rate': 9.599766580811334e-05, 'epoch': 0.35}\n",
            "{'loss': 6.0037, 'learning_rate': 9.598760463618803e-05, 'epoch': 0.35}\n",
            "{'loss': 5.7297, 'learning_rate': 9.597754346426272e-05, 'epoch': 0.35}\n",
            "{'loss': 5.0606, 'learning_rate': 9.596748229233741e-05, 'epoch': 0.35}\n",
            "{'loss': 5.2201, 'learning_rate': 9.59574211204121e-05, 'epoch': 0.35}\n",
            "{'loss': 5.0979, 'learning_rate': 9.594735994848681e-05, 'epoch': 0.35}\n",
            "{'loss': 4.4925, 'learning_rate': 9.59372987765615e-05, 'epoch': 0.35}\n",
            "{'loss': 3.9922, 'learning_rate': 9.59272376046362e-05, 'epoch': 0.35}\n",
            "{'loss': 4.0403, 'learning_rate': 9.591717643271089e-05, 'epoch': 0.36}\n",
            "{'loss': 4.1308, 'learning_rate': 9.590711526078559e-05, 'epoch': 0.36}\n",
            "{'loss': 6.6633, 'learning_rate': 9.589705408886027e-05, 'epoch': 0.36}\n",
            "{'loss': 6.4072, 'learning_rate': 9.588699291693497e-05, 'epoch': 0.36}\n",
            "{'loss': 6.2812, 'learning_rate': 9.587693174500967e-05, 'epoch': 0.36}\n",
            "{'loss': 5.9581, 'learning_rate': 9.586687057308436e-05, 'epoch': 0.36}\n",
            "{'loss': 5.4266, 'learning_rate': 9.585680940115905e-05, 'epoch': 0.36}\n",
            "{'loss': 5.2554, 'learning_rate': 9.584674822923374e-05, 'epoch': 0.36}\n",
            "{'loss': 4.6167, 'learning_rate': 9.583668705730843e-05, 'epoch': 0.36}\n",
            "{'loss': 4.423, 'learning_rate': 9.582662588538314e-05, 'epoch': 0.36}\n",
            "{'loss': 4.3434, 'learning_rate': 9.581656471345782e-05, 'epoch': 0.36}\n",
            "{'loss': 3.3299, 'learning_rate': 9.580650354153252e-05, 'epoch': 0.36}\n",
            "{'loss': 6.1515, 'learning_rate': 9.579644236960722e-05, 'epoch': 0.36}\n",
            "{'loss': 5.687, 'learning_rate': 9.578638119768191e-05, 'epoch': 0.36}\n",
            "{'loss': 6.537, 'learning_rate': 9.57763200257566e-05, 'epoch': 0.36}\n",
            "{'loss': 5.2924, 'learning_rate': 9.57662588538313e-05, 'epoch': 0.36}\n",
            "{'loss': 5.6188, 'learning_rate': 9.5756197681906e-05, 'epoch': 0.36}\n",
            "{'loss': 4.7515, 'learning_rate': 9.574613650998069e-05, 'epoch': 0.36}\n",
            "{'loss': 4.4314, 'learning_rate': 9.573607533805538e-05, 'epoch': 0.36}\n",
            "{'loss': 4.7035, 'learning_rate': 9.572601416613007e-05, 'epoch': 0.36}\n",
            "{'loss': 5.4448, 'learning_rate': 9.571595299420478e-05, 'epoch': 0.36}\n",
            "{'loss': 3.8077, 'learning_rate': 9.570589182227946e-05, 'epoch': 0.36}\n",
            "{'loss': 6.4617, 'learning_rate': 9.569583065035416e-05, 'epoch': 0.36}\n",
            "{'loss': 5.6574, 'learning_rate': 9.568576947842885e-05, 'epoch': 0.36}\n",
            "{'loss': 5.8537, 'learning_rate': 9.567570830650355e-05, 'epoch': 0.36}\n",
            "{'loss': 5.42, 'learning_rate': 9.566564713457824e-05, 'epoch': 0.36}\n",
            "{'loss': 5.0015, 'learning_rate': 9.565558596265294e-05, 'epoch': 0.37}\n",
            "{'loss': 4.9561, 'learning_rate': 9.564552479072762e-05, 'epoch': 0.37}\n",
            "{'loss': 4.6481, 'learning_rate': 9.563546361880233e-05, 'epoch': 0.37}\n",
            "{'loss': 4.481, 'learning_rate': 9.562540244687702e-05, 'epoch': 0.37}\n",
            "{'loss': 3.8735, 'learning_rate': 9.561534127495171e-05, 'epoch': 0.37}\n",
            "{'loss': 3.4289, 'learning_rate': 9.56052801030264e-05, 'epoch': 0.37}\n",
            "{'loss': 5.8396, 'learning_rate': 9.55952189311011e-05, 'epoch': 0.37}\n",
            "{'loss': 6.3447, 'learning_rate': 9.558515775917579e-05, 'epoch': 0.37}\n",
            "{'loss': 6.2216, 'learning_rate': 9.557509658725049e-05, 'epoch': 0.37}\n",
            "{'loss': 5.7036, 'learning_rate': 9.556503541532518e-05, 'epoch': 0.37}\n",
            "{'loss': 5.1292, 'learning_rate': 9.555497424339988e-05, 'epoch': 0.37}\n",
            "{'loss': 4.9256, 'learning_rate': 9.554491307147457e-05, 'epoch': 0.37}\n",
            "{'loss': 4.7142, 'learning_rate': 9.553485189954926e-05, 'epoch': 0.37}\n",
            "{'loss': 4.6914, 'learning_rate': 9.552479072762396e-05, 'epoch': 0.37}\n",
            "{'loss': 4.1457, 'learning_rate': 9.551472955569866e-05, 'epoch': 0.37}\n",
            "{'loss': 3.5097, 'learning_rate': 9.550466838377335e-05, 'epoch': 0.37}\n",
            "  9% 4854/52312 [30:14<6:01:55,  2.19it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/XLM-Finetune/main2.py"
      ],
      "metadata": {
        "id": "6JCmunaw6G3h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da8099ed-208c-4363-d47d-403736c6486c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-15 15:25:31.553001: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-15 15:25:31.553087: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-15 15:25:31.555331: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-15 15:25:33.120414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of MRCQuestionAnswering were not initialized from the model checkpoint at xlm-roberta-large and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "MRCQuestionAnswering(\n",
            "  (roberta): RobertaModel(\n",
            "    (embeddings): RobertaEmbeddings(\n",
            "      (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
            "      (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
            "      (token_type_embeddings): Embedding(1, 1024)\n",
            "      (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): RobertaEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0-23): 24 x RobertaLayer(\n",
            "          (attention): RobertaAttention(\n",
            "            (self): RobertaSelfAttention(\n",
            "              (query): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
            "              (key): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
            "              (value): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): RobertaSelfOutput(\n",
            "              (dense): Linear4bit(in_features=1024, out_features=1024, bias=True)\n",
            "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): RobertaIntermediate(\n",
            "            (dense): Linear4bit(in_features=1024, out_features=4096, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): RobertaOutput(\n",
            "            (dense): Linear4bit(in_features=4096, out_features=1024, bias=True)\n",
            "            (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (qa_outputs): Linear(in_features=1024, out_features=2, bias=True)\n",
            ")\n",
            "Train set:  13919\n",
            "Valid set:  1547\n",
            "Map (num_proc=10): 100% 13919/13919 [02:01<00:00, 114.99 examples/s]\n",
            "Filter (num_proc=10): 100% 13919/13919 [00:05<00:00, 2386.36 examples/s]\n",
            "Train set:  13089\n",
            "Valid set:  1455\n",
            "  0% 0/26178 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "{'loss': 5.7082, 'learning_rate': 7.639419404125288e-07, 'epoch': 0.0}\n",
            "{'loss': 5.7953, 'learning_rate': 1.5278838808250575e-06, 'epoch': 0.0}\n",
            "{'loss': 5.5258, 'learning_rate': 2.291825821237586e-06, 'epoch': 0.0}\n",
            "{'loss': 5.4543, 'learning_rate': 3.055767761650115e-06, 'epoch': 0.0}\n",
            "{'loss': 5.0891, 'learning_rate': 3.819709702062643e-06, 'epoch': 0.0}\n",
            "{'loss': 5.0695, 'learning_rate': 4.583651642475172e-06, 'epoch': 0.0}\n",
            "{'loss': 4.7297, 'learning_rate': 5.347593582887701e-06, 'epoch': 0.0}\n",
            "{'loss': 4.2422, 'learning_rate': 6.11153552330023e-06, 'epoch': 0.0}\n",
            "{'loss': 3.8975, 'learning_rate': 6.8754774637127585e-06, 'epoch': 0.0}\n",
            "{'loss': 3.3428, 'learning_rate': 7.639419404125286e-06, 'epoch': 0.0}\n",
            "{'loss': 5.6398, 'learning_rate': 8.403361344537817e-06, 'epoch': 0.0}\n",
            "{'loss': 5.4031, 'learning_rate': 9.167303284950345e-06, 'epoch': 0.0}\n",
            "{'loss': 5.3559, 'learning_rate': 9.931245225362872e-06, 'epoch': 0.0}\n",
            "{'loss': 5.0039, 'learning_rate': 1.0695187165775402e-05, 'epoch': 0.01}\n",
            "{'loss': 5.1246, 'learning_rate': 1.1459129106187929e-05, 'epoch': 0.01}\n",
            "{'loss': 4.7824, 'learning_rate': 1.222307104660046e-05, 'epoch': 0.01}\n",
            "{'loss': 4.6328, 'learning_rate': 1.2987012987012986e-05, 'epoch': 0.01}\n",
            "{'loss': 4.4516, 'learning_rate': 1.3750954927425517e-05, 'epoch': 0.01}\n",
            "{'loss': 4.1613, 'learning_rate': 1.4514896867838046e-05, 'epoch': 0.01}\n",
            "{'loss': 3.4338, 'learning_rate': 1.5278838808250572e-05, 'epoch': 0.01}\n",
            "{'loss': 5.6398, 'learning_rate': 1.60427807486631e-05, 'epoch': 0.01}\n",
            "{'loss': 5.7527, 'learning_rate': 1.6806722689075634e-05, 'epoch': 0.01}\n",
            "{'loss': 5.4262, 'learning_rate': 1.757066462948816e-05, 'epoch': 0.01}\n",
            "{'loss': 5.2121, 'learning_rate': 1.833460656990069e-05, 'epoch': 0.01}\n",
            "{'loss': 4.8453, 'learning_rate': 1.9098548510313215e-05, 'epoch': 0.01}\n",
            "{'loss': 4.6375, 'learning_rate': 1.9862490450725744e-05, 'epoch': 0.01}\n",
            "{'loss': 4.6113, 'learning_rate': 2.0626432391138277e-05, 'epoch': 0.01}\n",
            "{'loss': 4.3117, 'learning_rate': 2.1390374331550803e-05, 'epoch': 0.01}\n",
            "{'loss': 4.2324, 'learning_rate': 2.2154316271963332e-05, 'epoch': 0.01}\n",
            "{'loss': 3.5998, 'learning_rate': 2.2918258212375858e-05, 'epoch': 0.01}\n",
            "{'loss': 5.7016, 'learning_rate': 2.3682200152788388e-05, 'epoch': 0.01}\n",
            "{'loss': 5.5938, 'learning_rate': 2.444614209320092e-05, 'epoch': 0.01}\n",
            "{'loss': 5.7086, 'learning_rate': 2.5057295645530942e-05, 'epoch': 0.01}\n",
            "{'loss': 5.3555, 'learning_rate': 2.5821237585943468e-05, 'epoch': 0.01}\n",
            "{'loss': 4.9371, 'learning_rate': 2.6585179526355997e-05, 'epoch': 0.01}\n",
            "{'loss': 4.7199, 'learning_rate': 2.734912146676853e-05, 'epoch': 0.01}\n",
            "{'loss': 4.6824, 'learning_rate': 2.8113063407181056e-05, 'epoch': 0.01}\n",
            "{'loss': 4.4465, 'learning_rate': 2.8877005347593582e-05, 'epoch': 0.01}\n",
            "{'loss': 4.5402, 'learning_rate': 2.9640947288006115e-05, 'epoch': 0.01}\n",
            "{'loss': 3.915, 'learning_rate': 3.0404889228418644e-05, 'epoch': 0.02}\n",
            "{'loss': 5.9523, 'learning_rate': 3.1168831168831166e-05, 'epoch': 0.02}\n",
            "{'loss': 5.5727, 'learning_rate': 3.1932773109243696e-05, 'epoch': 0.02}\n",
            "{'loss': 5.4168, 'learning_rate': 3.269671504965623e-05, 'epoch': 0.02}\n",
            "{'loss': 5.1555, 'learning_rate': 3.3460656990068754e-05, 'epoch': 0.02}\n",
            "{'loss': 5.016, 'learning_rate': 3.4224598930481284e-05, 'epoch': 0.02}\n",
            "{'loss': 4.8207, 'learning_rate': 3.498854087089381e-05, 'epoch': 0.02}\n",
            "{'loss': 4.6359, 'learning_rate': 3.575248281130634e-05, 'epoch': 0.02}\n",
            "{'loss': 4.4066, 'learning_rate': 3.651642475171887e-05, 'epoch': 0.02}\n",
            "{'loss': 4.1023, 'learning_rate': 3.72803666921314e-05, 'epoch': 0.02}\n",
            "{'loss': 3.6281, 'learning_rate': 3.804430863254393e-05, 'epoch': 0.02}\n",
            "{'loss': 5.6937, 'learning_rate': 3.880825057295646e-05, 'epoch': 0.02}\n",
            "{'loss': 5.6723, 'learning_rate': 3.957219251336899e-05, 'epoch': 0.02}\n",
            "{'loss': 5.3113, 'learning_rate': 4.033613445378152e-05, 'epoch': 0.02}\n",
            "{'loss': 5.125, 'learning_rate': 4.110007639419404e-05, 'epoch': 0.02}\n",
            "{'loss': 4.8492, 'learning_rate': 4.186401833460657e-05, 'epoch': 0.02}\n",
            "{'loss': 4.6227, 'learning_rate': 4.26279602750191e-05, 'epoch': 0.02}\n",
            "{'loss': 4.627, 'learning_rate': 4.339190221543163e-05, 'epoch': 0.02}\n",
            "{'loss': 4.3809, 'learning_rate': 4.415584415584416e-05, 'epoch': 0.02}\n",
            "{'loss': 4.0369, 'learning_rate': 4.491978609625669e-05, 'epoch': 0.02}\n",
            "{'loss': 3.4367, 'learning_rate': 4.5683728036669216e-05, 'epoch': 0.02}\n",
            "{'loss': 5.8023, 'learning_rate': 4.6447669977081745e-05, 'epoch': 0.02}\n",
            "{'loss': 5.7848, 'learning_rate': 4.7211611917494275e-05, 'epoch': 0.02}\n",
            "{'loss': 5.625, 'learning_rate': 4.7975553857906804e-05, 'epoch': 0.02}\n",
            "{'loss': 5.302, 'learning_rate': 4.8739495798319326e-05, 'epoch': 0.02}\n",
            "{'loss': 4.9969, 'learning_rate': 4.950343773873186e-05, 'epoch': 0.02}\n",
            "{'loss': 4.6332, 'learning_rate': 5.026737967914439e-05, 'epoch': 0.03}\n",
            "{'loss': 4.5902, 'learning_rate': 5.1031321619556914e-05, 'epoch': 0.03}\n",
            "{'loss': 4.3035, 'learning_rate': 5.1795263559969444e-05, 'epoch': 0.03}\n",
            "{'loss': 3.9963, 'learning_rate': 5.255920550038197e-05, 'epoch': 0.03}\n",
            "{'loss': 3.2191, 'learning_rate': 5.332314744079451e-05, 'epoch': 0.03}\n",
            "{'loss': 5.5871, 'learning_rate': 5.408708938120703e-05, 'epoch': 0.03}\n",
            "{'loss': 5.7164, 'learning_rate': 5.485103132161956e-05, 'epoch': 0.03}\n",
            "{'loss': 5.6684, 'learning_rate': 5.561497326203209e-05, 'epoch': 0.03}\n",
            "{'loss': 5.3117, 'learning_rate': 5.637891520244461e-05, 'epoch': 0.03}\n",
            "{'loss': 5.0242, 'learning_rate': 5.714285714285714e-05, 'epoch': 0.03}\n",
            "{'loss': 4.9387, 'learning_rate': 5.790679908326967e-05, 'epoch': 0.03}\n",
            "{'loss': 4.3535, 'learning_rate': 5.867074102368221e-05, 'epoch': 0.03}\n",
            "{'loss': 4.243, 'learning_rate': 5.9434682964094736e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4717, 'learning_rate': 6.019862490450726e-05, 'epoch': 0.03}\n",
            "{'loss': 2.9979, 'learning_rate': 6.096256684491979e-05, 'epoch': 0.03}\n",
            "{'loss': 5.7113, 'learning_rate': 6.172650878533232e-05, 'epoch': 0.03}\n",
            "{'loss': 5.4879, 'learning_rate': 6.249045072574485e-05, 'epoch': 0.03}\n",
            "{'loss': 5.377, 'learning_rate': 6.310160427807486e-05, 'epoch': 0.03}\n",
            "{'loss': 4.9527, 'learning_rate': 6.386554621848739e-05, 'epoch': 0.03}\n",
            "{'loss': 4.7316, 'learning_rate': 6.462948815889993e-05, 'epoch': 0.03}\n",
            "{'loss': 4.8617, 'learning_rate': 6.539343009931246e-05, 'epoch': 0.03}\n",
            "{'loss': 4.7031, 'learning_rate': 6.615737203972498e-05, 'epoch': 0.03}\n",
            "{'loss': 4.1365, 'learning_rate': 6.692131398013751e-05, 'epoch': 0.03}\n",
            "{'loss': 4.0713, 'learning_rate': 6.768525592055004e-05, 'epoch': 0.03}\n",
            "{'loss': 3.4412, 'learning_rate': 6.844919786096257e-05, 'epoch': 0.03}\n",
            "{'loss': 5.577, 'learning_rate': 6.921313980137511e-05, 'epoch': 0.03}\n",
            "{'loss': 5.7098, 'learning_rate': 6.997708174178763e-05, 'epoch': 0.04}\n",
            "{'loss': 5.4551, 'learning_rate': 7.074102368220015e-05, 'epoch': 0.04}\n",
            "{'loss': 5.2543, 'learning_rate': 7.150496562261268e-05, 'epoch': 0.04}\n",
            "{'loss': 4.802, 'learning_rate': 7.226890756302521e-05, 'epoch': 0.04}\n",
            "{'loss': 4.5152, 'learning_rate': 7.303284950343774e-05, 'epoch': 0.04}\n",
            "{'loss': 4.5285, 'learning_rate': 7.379679144385027e-05, 'epoch': 0.04}\n",
            "{'loss': 4.2316, 'learning_rate': 7.45607333842628e-05, 'epoch': 0.04}\n",
            "{'loss': 4.0941, 'learning_rate': 7.532467532467533e-05, 'epoch': 0.04}\n",
            "{'loss': 3.2354, 'learning_rate': 7.608861726508786e-05, 'epoch': 0.04}\n",
            "{'loss': 5.4813, 'learning_rate': 7.669977081741789e-05, 'epoch': 0.04}\n",
            "{'loss': 4.9777, 'learning_rate': 7.74637127578304e-05, 'epoch': 0.04}\n",
            "{'loss': 4.69, 'learning_rate': 7.807486631016043e-05, 'epoch': 0.04}\n",
            "{'loss': 4.6844, 'learning_rate': 7.883880825057296e-05, 'epoch': 0.04}\n",
            "{'loss': 4.399, 'learning_rate': 7.960275019098549e-05, 'epoch': 0.04}\n",
            "{'loss': 4.3535, 'learning_rate': 8.036669213139801e-05, 'epoch': 0.04}\n",
            "{'loss': 3.9844, 'learning_rate': 8.113063407181055e-05, 'epoch': 0.04}\n",
            "{'loss': 3.7002, 'learning_rate': 8.189457601222308e-05, 'epoch': 0.04}\n",
            "{'loss': 3.4012, 'learning_rate': 8.265851795263561e-05, 'epoch': 0.04}\n",
            "{'loss': 2.6857, 'learning_rate': 8.342245989304814e-05, 'epoch': 0.04}\n",
            "{'loss': 5.3027, 'learning_rate': 8.418640183346065e-05, 'epoch': 0.04}\n",
            "{'loss': 4.4182, 'learning_rate': 8.495034377387318e-05, 'epoch': 0.04}\n",
            "{'loss': 5.5066, 'learning_rate': 8.571428571428571e-05, 'epoch': 0.04}\n",
            "{'loss': 4.708, 'learning_rate': 8.647822765469826e-05, 'epoch': 0.04}\n",
            "{'loss': 5.908, 'learning_rate': 8.708938120702827e-05, 'epoch': 0.04}\n",
            "{'loss': 4.5041, 'learning_rate': 8.78533231474408e-05, 'epoch': 0.04}\n",
            "{'loss': 5.0953, 'learning_rate': 8.861726508785333e-05, 'epoch': 0.04}\n",
            "{'loss': 2.6687, 'learning_rate': 8.938120702826586e-05, 'epoch': 0.05}\n",
            "{'loss': 3.1598, 'learning_rate': 9.014514896867839e-05, 'epoch': 0.05}\n",
            "{'loss': 2.3533, 'learning_rate': 9.090909090909092e-05, 'epoch': 0.05}\n",
            "{'loss': 4.9539, 'learning_rate': 9.167303284950343e-05, 'epoch': 0.05}\n",
            "{'loss': 4.9521, 'learning_rate': 9.243697478991598e-05, 'epoch': 0.05}\n",
            "{'loss': 4.7934, 'learning_rate': 9.32009167303285e-05, 'epoch': 0.05}\n",
            "{'loss': 4.2715, 'learning_rate': 9.396485867074103e-05, 'epoch': 0.05}\n",
            "{'loss': 5.0809, 'learning_rate': 9.472880061115355e-05, 'epoch': 0.05}\n",
            "{'loss': 3.4816, 'learning_rate': 9.549274255156608e-05, 'epoch': 0.05}\n",
            "{'loss': 4.2689, 'learning_rate': 9.625668449197861e-05, 'epoch': 0.05}\n",
            "{'loss': 2.9857, 'learning_rate': 9.702062643239115e-05, 'epoch': 0.05}\n",
            "{'loss': 2.7347, 'learning_rate': 9.778456837280368e-05, 'epoch': 0.05}\n",
            "{'loss': 2.6561, 'learning_rate': 9.85485103132162e-05, 'epoch': 0.05}\n",
            "{'loss': 4.4482, 'learning_rate': 9.931245225362873e-05, 'epoch': 0.05}\n",
            "{'loss': 6.2287, 'learning_rate': 0.00010007639419404127, 'epoch': 0.05}\n",
            "{'loss': 4.4205, 'learning_rate': 0.00010084033613445378, 'epoch': 0.05}\n",
            "{'loss': 4.2717, 'learning_rate': 0.00010160427807486633, 'epoch': 0.05}\n",
            "{'loss': 4.5121, 'learning_rate': 0.00010236822001527884, 'epoch': 0.05}\n",
            "{'loss': 3.6437, 'learning_rate': 0.00010313216195569137, 'epoch': 0.05}\n",
            "{'loss': 3.2702, 'learning_rate': 0.00010389610389610389, 'epoch': 0.05}\n",
            "{'loss': 3.577, 'learning_rate': 0.00010466004583651643, 'epoch': 0.05}\n",
            "{'loss': 3.3703, 'learning_rate': 0.00010542398777692897, 'epoch': 0.05}\n",
            "{'loss': 1.9737, 'learning_rate': 0.00010618792971734149, 'epoch': 0.05}\n",
            "{'loss': 5.0033, 'learning_rate': 0.00010695187165775402, 'epoch': 0.05}\n",
            "{'loss': 5.8119, 'learning_rate': 0.00010771581359816653, 'epoch': 0.05}\n",
            "{'loss': 5.5635, 'learning_rate': 0.00010847975553857908, 'epoch': 0.05}\n",
            "{'loss': 4.5638, 'learning_rate': 0.00010924369747899159, 'epoch': 0.06}\n",
            "{'loss': 4.5771, 'learning_rate': 0.00011000763941940414, 'epoch': 0.06}\n",
            "{'loss': 4.7918, 'learning_rate': 0.00011077158135981666, 'epoch': 0.06}\n",
            "{'loss': 3.4482, 'learning_rate': 0.00011153552330022918, 'epoch': 0.06}\n",
            "{'loss': 3.1699, 'learning_rate': 0.00011229946524064172, 'epoch': 0.06}\n",
            "{'loss': 3.2377, 'learning_rate': 0.00011306340718105424, 'epoch': 0.06}\n",
            "{'loss': 2.507, 'learning_rate': 0.00011382734912146677, 'epoch': 0.06}\n",
            "{'loss': 6.1547, 'learning_rate': 0.00011459129106187931, 'epoch': 0.06}\n",
            "{'loss': 4.3145, 'learning_rate': 0.00011535523300229183, 'epoch': 0.06}\n",
            "{'loss': 4.5555, 'learning_rate': 0.00011611917494270437, 'epoch': 0.06}\n",
            "{'loss': 5.3076, 'learning_rate': 0.00011688311688311689, 'epoch': 0.06}\n",
            "{'loss': 4.1135, 'learning_rate': 0.00011764705882352942, 'epoch': 0.06}\n",
            "{'loss': 4.9186, 'learning_rate': 0.00011841100076394193, 'epoch': 0.06}\n",
            "{'loss': 3.9813, 'learning_rate': 0.00011917494270435447, 'epoch': 0.06}\n",
            "{'loss': 3.0525, 'learning_rate': 0.00011993888464476702, 'epoch': 0.06}\n",
            "{'loss': 2.112, 'learning_rate': 0.00012070282658517953, 'epoch': 0.06}\n",
            "  3% 798/26178 [03:35<1:39:06,  4.27it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bt6jVRP8g6da"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}